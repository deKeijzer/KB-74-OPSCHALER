{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "mpl.style.use('default')\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow backend initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of GPUs available: 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup multi GPU usage\n",
    "\n",
    "Example usage:\n",
    "model = Sequential()\n",
    "...\n",
    "multi_model = multi_gpu_model(model, gpus=num_gpu)\n",
    "multi_model.fit()\n",
    "\n",
    "About memory usage:\n",
    "https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# IMPORTANT: Tells tf to not occupy a specific amount of memory\n",
    "from keras.backend.tensorflow_backend import set_session  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
    "sess = tf.Session(config=config)  \n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras.\n",
    "\n",
    "\n",
    "# getting the number of GPUs \n",
    "def get_available_gpus():\n",
    "   local_device_protos = device_lib.list_local_devices()\n",
    "   return [x.name for x in local_device_protos if x.device_type    == 'GPU']\n",
    "num_gpu = len(get_available_gpus())\n",
    "print('Amount of GPUs available: %s' % num_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    \"\"\"\n",
    "    Reduces memory footprint of the input dataframe.\n",
    "    Changes float64 columns to float32 dtype.\n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    memory_before = df.memory_usage(deep=False).sum() / 2**30 # convert bytes to GB\n",
    "\n",
    "    for column in tqdm(columns):\n",
    "        if df[column].dtype == 'float64':\n",
    "            df[column] = df[column].astype('float32')\n",
    "        \n",
    "    memory_after = df.memory_usage(deep=False).sum() / 2**30 # convert bytes to GB\n",
    "    print('Memory uasge reduced from %.3f GB to %.3f GB' % (memory_before, memory_after))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataframe for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 528 ms, sys: 52.9 ms, total: 581 ms\n",
      "Wall time: 551 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('//datc//opschaler//combined_gas_smart_weather_dfs//processed//all_dwellings_combined_hour.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "df = df.set_index(['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eMeter</th>\n",
       "      <th>eMeterReturn</th>\n",
       "      <th>eMeterLow</th>\n",
       "      <th>eMeterLowReturn</th>\n",
       "      <th>ePower</th>\n",
       "      <th>ePowerReturn</th>\n",
       "      <th>gasMeter</th>\n",
       "      <th>gasPower</th>\n",
       "      <th>DD</th>\n",
       "      <th>DR</th>\n",
       "      <th>...</th>\n",
       "      <th>Q</th>\n",
       "      <th>RG</th>\n",
       "      <th>SQ</th>\n",
       "      <th>T</th>\n",
       "      <th>T10</th>\n",
       "      <th>TD</th>\n",
       "      <th>U</th>\n",
       "      <th>VV</th>\n",
       "      <th>WW</th>\n",
       "      <th>dwelling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-07 15:00:00</th>\n",
       "      <td>625.004578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.501007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.44101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.450012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.631617</td>\n",
       "      <td>8.733334</td>\n",
       "      <td>9.133333</td>\n",
       "      <td>4.883333</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>31916.666016</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>P01S01W7548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-07 16:00:00</th>\n",
       "      <td>625.212280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.501007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.994446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.44101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.200012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.116667</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>77.166664</td>\n",
       "      <td>23800.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>P01S01W7548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-07 17:00:00</th>\n",
       "      <td>625.578430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.501007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.722229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.44101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.866669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.936100</td>\n",
       "      <td>7.866667</td>\n",
       "      <td>8.450000</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>78.833336</td>\n",
       "      <td>22233.333984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>P01S01W7548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-07 18:00:00</th>\n",
       "      <td>625.763977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.501007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.624283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.44101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.633331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.833336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.066667</td>\n",
       "      <td>6.816667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>82.833336</td>\n",
       "      <td>20266.666016</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>P01S01W7548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-07 19:00:00</th>\n",
       "      <td>625.877808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.501007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.376038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.44101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.783325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.616667</td>\n",
       "      <td>6.016667</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>84.666664</td>\n",
       "      <td>17433.333984</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>P01S01W7548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         eMeter  eMeterReturn   eMeterLow  eMeterLowReturn  \\\n",
       "datetime                                                                     \n",
       "2017-03-07 15:00:00  625.004578           0.0  359.501007              0.0   \n",
       "2017-03-07 16:00:00  625.212280           0.0  359.501007              0.0   \n",
       "2017-03-07 17:00:00  625.578430           0.0  359.501007              0.0   \n",
       "2017-03-07 18:00:00  625.763977           0.0  359.501007              0.0   \n",
       "2017-03-07 19:00:00  625.877808           0.0  359.501007              0.0   \n",
       "\n",
       "                         ePower  ePowerReturn   gasMeter  gasPower  \\\n",
       "datetime                                                             \n",
       "2017-03-07 15:00:00  192.500000           0.0  307.44101       0.0   \n",
       "2017-03-07 16:00:00  383.994446           0.0  307.44101       0.0   \n",
       "2017-03-07 17:00:00  277.722229           0.0  307.44101       0.0   \n",
       "2017-03-07 18:00:00  143.624283           0.0  307.44101       0.0   \n",
       "2017-03-07 19:00:00  143.376038           0.0  307.44101       0.0   \n",
       "\n",
       "                             DD   DR     ...                Q   RG         SQ  \\\n",
       "datetime                                 ...                                    \n",
       "2017-03-07 15:00:00  305.450012  0.0     ...       319.000000  0.0   7.631617   \n",
       "2017-03-07 16:00:00  288.200012  0.0     ...       391.000000  0.0  10.000000   \n",
       "2017-03-07 17:00:00  285.866669  0.0     ...       179.000000  0.0   2.936100   \n",
       "2017-03-07 18:00:00  286.633331  0.0     ...        65.833336  0.0   5.000000   \n",
       "2017-03-07 19:00:00  278.783325  0.0     ...         7.500000  0.0   0.000000   \n",
       "\n",
       "                            T        T10        TD          U            VV  \\\n",
       "datetime                                                                      \n",
       "2017-03-07 15:00:00  8.733334   9.133333  4.883333  76.500000  31916.666016   \n",
       "2017-03-07 16:00:00  9.116667  10.750000  5.416667  77.166664  23800.000000   \n",
       "2017-03-07 17:00:00  7.866667   8.450000  4.550000  78.833336  22233.333984   \n",
       "2017-03-07 18:00:00  7.066667   6.816667  4.433333  82.833336  20266.666016   \n",
       "2017-03-07 19:00:00  6.616667   6.016667  4.300000  84.666664  17433.333984   \n",
       "\n",
       "                           WW     dwelling  \n",
       "datetime                                    \n",
       "2017-03-07 15:00:00  1.333333  P01S01W7548  \n",
       "2017-03-07 16:00:00  2.666667  P01S01W7548  \n",
       "2017-03-07 17:00:00  1.000000  P01S01W7548  \n",
       "2017-03-07 18:00:00  2.500000  P01S01W7548  \n",
       "2017-03-07 19:00:00  2.833333  P01S01W7548  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = reduce_memory(df_10s) # converts float64 to float32\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eMeter</th>\n",
       "      <th>eMeterReturn</th>\n",
       "      <th>eMeterLow</th>\n",
       "      <th>eMeterLowReturn</th>\n",
       "      <th>ePower</th>\n",
       "      <th>ePowerReturn</th>\n",
       "      <th>gasMeter</th>\n",
       "      <th>gasPower</th>\n",
       "      <th>DD</th>\n",
       "      <th>DR</th>\n",
       "      <th>...</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>RG</th>\n",
       "      <th>SQ</th>\n",
       "      <th>T</th>\n",
       "      <th>T10</th>\n",
       "      <th>TD</th>\n",
       "      <th>U</th>\n",
       "      <th>VV</th>\n",
       "      <th>WW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116310.000000</td>\n",
       "      <td>116310.000000</td>\n",
       "      <td>116310.000000</td>\n",
       "      <td>116310.000000</td>\n",
       "      <td>116310.000000</td>\n",
       "      <td>116310.000000</td>\n",
       "      <td>116159.000000</td>\n",
       "      <td>115271.000000</td>\n",
       "      <td>126879.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>126885.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "      <td>126918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2254.009894</td>\n",
       "      <td>734.602074</td>\n",
       "      <td>2553.808870</td>\n",
       "      <td>337.142188</td>\n",
       "      <td>306.854612</td>\n",
       "      <td>91.833729</td>\n",
       "      <td>1910.555321</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>200.732522</td>\n",
       "      <td>36.635836</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.346305</td>\n",
       "      <td>164.890896</td>\n",
       "      <td>0.089398</td>\n",
       "      <td>2.618587</td>\n",
       "      <td>12.659400</td>\n",
       "      <td>12.065308</td>\n",
       "      <td>8.592021</td>\n",
       "      <td>77.504207</td>\n",
       "      <td>25513.388346</td>\n",
       "      <td>10.695239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1438.333101</td>\n",
       "      <td>1568.532075</td>\n",
       "      <td>1568.656696</td>\n",
       "      <td>715.891360</td>\n",
       "      <td>306.335392</td>\n",
       "      <td>385.189732</td>\n",
       "      <td>963.505715</td>\n",
       "      <td>0.180611</td>\n",
       "      <td>86.342213</td>\n",
       "      <td>116.541015</td>\n",
       "      <td>...</td>\n",
       "      <td>7.774604</td>\n",
       "      <td>223.271878</td>\n",
       "      <td>0.504380</td>\n",
       "      <td>3.761346</td>\n",
       "      <td>5.287665</td>\n",
       "      <td>6.282919</td>\n",
       "      <td>4.399467</td>\n",
       "      <td>14.602729</td>\n",
       "      <td>12841.003032</td>\n",
       "      <td>16.725095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.594465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.388000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>195.725006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>985.966675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>-5.916667</td>\n",
       "      <td>-3.133333</td>\n",
       "      <td>30.333334</td>\n",
       "      <td>142.333328</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1174.895020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1284.309570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.944202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.953003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.366669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.539978</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>67.333336</td>\n",
       "      <td>14900.000000</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1730.750732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2058.964233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.964706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1729.171997</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>219.949997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.599976</td>\n",
       "      <td>34.166668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.283334</td>\n",
       "      <td>11.816667</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>79.666664</td>\n",
       "      <td>25966.666016</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2886.669312</td>\n",
       "      <td>760.737244</td>\n",
       "      <td>3856.920044</td>\n",
       "      <td>301.908363</td>\n",
       "      <td>377.012100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2664.135010</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>262.466675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1022.833313</td>\n",
       "      <td>294.666656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.212033</td>\n",
       "      <td>16.450001</td>\n",
       "      <td>16.183332</td>\n",
       "      <td>12.233334</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>35783.332031</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6218.289062</td>\n",
       "      <td>7923.427246</td>\n",
       "      <td>7707.495117</td>\n",
       "      <td>3508.043945</td>\n",
       "      <td>4240.345703</td>\n",
       "      <td>5999.823242</td>\n",
       "      <td>4668.230957</td>\n",
       "      <td>2.692017</td>\n",
       "      <td>356.816650</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1037.833374</td>\n",
       "      <td>926.500000</td>\n",
       "      <td>18.166666</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.683332</td>\n",
       "      <td>32.466667</td>\n",
       "      <td>20.383333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49900.000000</td>\n",
       "      <td>81.800003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              eMeter   eMeterReturn      eMeterLow  eMeterLowReturn  \\\n",
       "count  116310.000000  116310.000000  116310.000000    116310.000000   \n",
       "mean     2254.009894     734.602074    2553.808870       337.142188   \n",
       "std      1438.333101    1568.532075    1568.656696       715.891360   \n",
       "min        23.594465       0.000000      32.388000         0.000000   \n",
       "25%      1174.895020       0.000000    1284.309570         0.000000   \n",
       "50%      1730.750732       0.000000    2058.964233         0.000000   \n",
       "75%      2886.669312     760.737244    3856.920044       301.908363   \n",
       "max      6218.289062    7923.427246    7707.495117      3508.043945   \n",
       "\n",
       "              ePower   ePowerReturn       gasMeter       gasPower  \\\n",
       "count  116310.000000  116310.000000  116159.000000  115271.000000   \n",
       "mean      306.854612      91.833729    1910.555321       0.082981   \n",
       "std       306.335392     385.189732     963.505715       0.180611   \n",
       "min         0.000000       0.000000     195.725006       0.000000   \n",
       "25%       127.944202       0.000000    1121.953003       0.000000   \n",
       "50%       213.964706       0.000000    1729.171997       0.008057   \n",
       "75%       377.012100       0.000000    2664.135010       0.069092   \n",
       "max      4240.345703    5999.823242    4668.230957       2.692017   \n",
       "\n",
       "                  DD             DR      ...                    P  \\\n",
       "count  126879.000000  126918.000000      ...        126885.000000   \n",
       "mean      200.732522      36.635836      ...          1017.346305   \n",
       "std        86.342213     116.541015      ...             7.774604   \n",
       "min         1.850000       0.000000      ...           985.966675   \n",
       "25%       143.366669       0.000000      ...          1012.539978   \n",
       "50%       219.949997       0.000000      ...          1017.599976   \n",
       "75%       262.466675       0.000000      ...          1022.833313   \n",
       "max       356.816650     600.000000      ...          1037.833374   \n",
       "\n",
       "                   Q             RG             SQ              T  \\\n",
       "count  126918.000000  126918.000000  126918.000000  126918.000000   \n",
       "mean      164.890896       0.089398       2.618587      12.659400   \n",
       "std       223.271878       0.504380       3.761346       5.287665   \n",
       "min         0.000000       0.000000       0.000000      -1.700000   \n",
       "25%         0.166667       0.000000       0.000000       8.950000   \n",
       "50%        34.166668       0.000000       0.000000      12.283334   \n",
       "75%       294.666656       0.000000       5.212033      16.450001   \n",
       "max       926.500000      18.166666      10.000000      30.683332   \n",
       "\n",
       "                 T10             TD              U             VV  \\\n",
       "count  126918.000000  126918.000000  126918.000000  126918.000000   \n",
       "mean       12.065308       8.592021      77.504207   25513.388346   \n",
       "std         6.282919       4.399467      14.602729   12841.003032   \n",
       "min        -5.916667      -3.133333      30.333334     142.333328   \n",
       "25%         8.083333       4.950000      67.333336   14900.000000   \n",
       "50%        11.816667       8.760000      79.666664   25966.666016   \n",
       "75%        16.183332      12.233334      89.500000   35783.332031   \n",
       "max        32.466667      20.383333     100.000000   49900.000000   \n",
       "\n",
       "                  WW  \n",
       "count  126918.000000  \n",
       "mean       10.695239  \n",
       "std        16.725095  \n",
       "min         0.000000  \n",
       "25%         1.833333  \n",
       "50%         2.333333  \n",
       "75%        10.000000  \n",
       "max        81.800003  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(1234)\n",
    "\n",
    "def drop_duplicates(df):\n",
    "    print(\"Number of duplicates: {}\".format(len(df.index.get_duplicates())))\n",
    "    return df[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "def impute_missing(df):\n",
    "    # todo test with moving average / mean or something smarter than forward fill\n",
    "    print(\"Number of rows with nan: {}\".format(np.count_nonzero(df.isnull())))\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    return df\n",
    "    \n",
    "def first_order_difference(data, columns):\n",
    "    for column in columns:\n",
    "        data[column+'_d'] = data[column].diff(periods=1)\n",
    "    \n",
    "    return data.dropna()\n",
    "\n",
    "def derive_prediction_columns(data, column, horizons):\n",
    "    for look_ahead in horizons:\n",
    "        data['prediction_' + str(look_ahead)] = data[column].diff(periods=look_ahead).shift(-look_ahead)\n",
    "    \n",
    "    return data.dropna()\n",
    "\n",
    "def scale_features(scaler, features):\n",
    "    scaler.fit(features)\n",
    "    \n",
    "    scaled = scaler.transform(features)\n",
    "    scaled = pd.DataFrame(scaled, columns=features.columns)\n",
    "    \n",
    "    return scaled\n",
    "\n",
    "def inverse_prediction_scale(scaler, predictions, original_columns, column):\n",
    "    loc = original_columns.get_loc(column)\n",
    "    \n",
    "    inverted = np.zeros((len(predictions), len(original_columns)))\n",
    "    inverted[:,loc] = np.reshape(predictions, (predictions.shape[0],))\n",
    "    \n",
    "    inverted = scaler.inverse_transform(inverted)[:,loc]\n",
    "    \n",
    "    return inverted\n",
    "\n",
    "def invert_all_prediction_scaled(scaler, predictions, original_columns, horizons):\n",
    "    inverted = np.zeros(predictions.shape)\n",
    "    \n",
    "    for col_idx, horizon in enumerate(horizons):\n",
    "        inverted[:,col_idx] = inverse_prediction_scale(\n",
    "            scaler, predictions[:,col_idx], \n",
    "            original_columns,\n",
    "            \"prediction_\" + str(horizon))\n",
    "        \n",
    "    return inverted\n",
    "\n",
    "def inverse_prediction_difference(predictions, original):\n",
    "    return predictions + original\n",
    "\n",
    "def invert_all_prediction_differences(predictions, original):\n",
    "    inverted = predictions\n",
    "    \n",
    "    for col_idx, horizon in enumerate(horizons):\n",
    "        inverted[:, col_idx] = inverse_prediction_difference(predictions[:,col_idx], original)\n",
    "        \n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 6766\n",
      "Number of rows with nan: 9670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ePower</th>\n",
       "      <th>DD</th>\n",
       "      <th>FF</th>\n",
       "      <th>N</th>\n",
       "      <th>Q</th>\n",
       "      <th>RG</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>ePower_d</th>\n",
       "      <th>DD_d</th>\n",
       "      <th>FF_d</th>\n",
       "      <th>N_d</th>\n",
       "      <th>Q_d</th>\n",
       "      <th>RG_d</th>\n",
       "      <th>T_d</th>\n",
       "      <th>U_d</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>prediction_6</th>\n",
       "      <th>prediction_12</th>\n",
       "      <th>prediction_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "      <td>6.742000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.574540e-16</td>\n",
       "      <td>-1.251594e-16</td>\n",
       "      <td>1.253488e-16</td>\n",
       "      <td>7.843029e-16</td>\n",
       "      <td>-1.780194e-15</td>\n",
       "      <td>9.868997e-16</td>\n",
       "      <td>-7.371077e-16</td>\n",
       "      <td>-4.099690e-16</td>\n",
       "      <td>3.581630e-18</td>\n",
       "      <td>1.124714e-17</td>\n",
       "      <td>-4.248554e-18</td>\n",
       "      <td>-2.762384e-17</td>\n",
       "      <td>-1.066583e-17</td>\n",
       "      <td>7.476202e-19</td>\n",
       "      <td>2.116044e-17</td>\n",
       "      <td>3.231701e-18</td>\n",
       "      <td>-1.655372e-17</td>\n",
       "      <td>-8.521810e-18</td>\n",
       "      <td>1.626966e-17</td>\n",
       "      <td>-1.630259e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "      <td>1.000074e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.364053e+00</td>\n",
       "      <td>-2.576694e+00</td>\n",
       "      <td>-1.719718e+00</td>\n",
       "      <td>-1.404811e+00</td>\n",
       "      <td>-6.970709e-01</td>\n",
       "      <td>-2.005439e-01</td>\n",
       "      <td>-2.821695e+00</td>\n",
       "      <td>-3.469619e+00</td>\n",
       "      <td>-9.541238e+00</td>\n",
       "      <td>-8.008392e+00</td>\n",
       "      <td>-6.588333e+00</td>\n",
       "      <td>-3.918421e+00</td>\n",
       "      <td>-8.258100e+00</td>\n",
       "      <td>-2.520149e+01</td>\n",
       "      <td>-1.687002e+01</td>\n",
       "      <td>-9.618483e+00</td>\n",
       "      <td>-6.588261e+00</td>\n",
       "      <td>-3.914840e+00</td>\n",
       "      <td>-4.549679e+00</td>\n",
       "      <td>-5.121136e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.550285e-01</td>\n",
       "      <td>-5.215156e-01</td>\n",
       "      <td>-7.617805e-01</td>\n",
       "      <td>-1.194718e+00</td>\n",
       "      <td>-6.962972e-01</td>\n",
       "      <td>-2.005439e-01</td>\n",
       "      <td>-7.268147e-01</td>\n",
       "      <td>-6.638037e-01</td>\n",
       "      <td>-1.671773e-01</td>\n",
       "      <td>-1.623440e-01</td>\n",
       "      <td>-5.533517e-01</td>\n",
       "      <td>-2.615776e-01</td>\n",
       "      <td>-1.751082e-01</td>\n",
       "      <td>-6.511630e-19</td>\n",
       "      <td>-4.988388e-01</td>\n",
       "      <td>-5.126873e-01</td>\n",
       "      <td>-5.532996e-01</td>\n",
       "      <td>-6.431330e-01</td>\n",
       "      <td>-6.474076e-01</td>\n",
       "      <td>-6.229991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.765486e-01</td>\n",
       "      <td>2.035798e-01</td>\n",
       "      <td>-1.338532e-01</td>\n",
       "      <td>3.284536e-01</td>\n",
       "      <td>-5.868130e-01</td>\n",
       "      <td>-2.005439e-01</td>\n",
       "      <td>1.808337e-02</td>\n",
       "      <td>1.361521e-01</td>\n",
       "      <td>-1.243476e-04</td>\n",
       "      <td>1.139685e-02</td>\n",
       "      <td>-5.716653e-03</td>\n",
       "      <td>-3.745125e-04</td>\n",
       "      <td>5.655473e-04</td>\n",
       "      <td>-6.511630e-19</td>\n",
       "      <td>-3.374899e-02</td>\n",
       "      <td>-7.159847e-04</td>\n",
       "      <td>-6.326188e-03</td>\n",
       "      <td>3.432686e-02</td>\n",
       "      <td>3.232712e-03</td>\n",
       "      <td>-3.859763e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.426788e-01</td>\n",
       "      <td>6.773361e-01</td>\n",
       "      <td>5.833443e-01</td>\n",
       "      <td>9.587314e-01</td>\n",
       "      <td>4.737909e-01</td>\n",
       "      <td>-2.005439e-01</td>\n",
       "      <td>7.202606e-01</td>\n",
       "      <td>8.047722e-01</td>\n",
       "      <td>1.441562e-01</td>\n",
       "      <td>1.985938e-01</td>\n",
       "      <td>5.501658e-01</td>\n",
       "      <td>2.608286e-01</td>\n",
       "      <td>2.181613e-01</td>\n",
       "      <td>-6.511630e-19</td>\n",
       "      <td>4.485684e-01</td>\n",
       "      <td>5.112562e-01</td>\n",
       "      <td>5.502142e-01</td>\n",
       "      <td>6.441442e-01</td>\n",
       "      <td>6.676213e-01</td>\n",
       "      <td>6.328572e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.837927e+00</td>\n",
       "      <td>1.903296e+00</td>\n",
       "      <td>4.727001e+00</td>\n",
       "      <td>1.431440e+00</td>\n",
       "      <td>3.604149e+00</td>\n",
       "      <td>3.034254e+01</td>\n",
       "      <td>3.215164e+00</td>\n",
       "      <td>1.521151e+00</td>\n",
       "      <td>9.438599e+00</td>\n",
       "      <td>7.810349e+00</td>\n",
       "      <td>1.201366e+01</td>\n",
       "      <td>4.178875e+00</td>\n",
       "      <td>8.927989e+00</td>\n",
       "      <td>2.590784e+01</td>\n",
       "      <td>1.676119e+01</td>\n",
       "      <td>6.845087e+00</td>\n",
       "      <td>1.201367e+01</td>\n",
       "      <td>4.956720e+00</td>\n",
       "      <td>3.922944e+00</td>\n",
       "      <td>4.019212e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ePower            DD            FF             N             Q  \\\n",
       "count  6.742000e+03  6.742000e+03  6.742000e+03  6.742000e+03  6.742000e+03   \n",
       "mean   5.574540e-16 -1.251594e-16  1.253488e-16  7.843029e-16 -1.780194e-15   \n",
       "std    1.000074e+00  1.000074e+00  1.000074e+00  1.000074e+00  1.000074e+00   \n",
       "min   -1.364053e+00 -2.576694e+00 -1.719718e+00 -1.404811e+00 -6.970709e-01   \n",
       "25%   -6.550285e-01 -5.215156e-01 -7.617805e-01 -1.194718e+00 -6.962972e-01   \n",
       "50%   -1.765486e-01  2.035798e-01 -1.338532e-01  3.284536e-01 -5.868130e-01   \n",
       "75%    2.426788e-01  6.773361e-01  5.833443e-01  9.587314e-01  4.737909e-01   \n",
       "max    9.837927e+00  1.903296e+00  4.727001e+00  1.431440e+00  3.604149e+00   \n",
       "\n",
       "                 RG             T             U      ePower_d          DD_d  \\\n",
       "count  6.742000e+03  6.742000e+03  6.742000e+03  6.742000e+03  6.742000e+03   \n",
       "mean   9.868997e-16 -7.371077e-16 -4.099690e-16  3.581630e-18  1.124714e-17   \n",
       "std    1.000074e+00  1.000074e+00  1.000074e+00  1.000074e+00  1.000074e+00   \n",
       "min   -2.005439e-01 -2.821695e+00 -3.469619e+00 -9.541238e+00 -8.008392e+00   \n",
       "25%   -2.005439e-01 -7.268147e-01 -6.638037e-01 -1.671773e-01 -1.623440e-01   \n",
       "50%   -2.005439e-01  1.808337e-02  1.361521e-01 -1.243476e-04  1.139685e-02   \n",
       "75%   -2.005439e-01  7.202606e-01  8.047722e-01  1.441562e-01  1.985938e-01   \n",
       "max    3.034254e+01  3.215164e+00  1.521151e+00  9.438599e+00  7.810349e+00   \n",
       "\n",
       "               FF_d           N_d           Q_d          RG_d           T_d  \\\n",
       "count  6.742000e+03  6.742000e+03  6.742000e+03  6.742000e+03  6.742000e+03   \n",
       "mean  -4.248554e-18 -2.762384e-17 -1.066583e-17  7.476202e-19  2.116044e-17   \n",
       "std    1.000074e+00  1.000074e+00  1.000074e+00  1.000074e+00  1.000074e+00   \n",
       "min   -6.588333e+00 -3.918421e+00 -8.258100e+00 -2.520149e+01 -1.687002e+01   \n",
       "25%   -5.533517e-01 -2.615776e-01 -1.751082e-01 -6.511630e-19 -4.988388e-01   \n",
       "50%   -5.716653e-03 -3.745125e-04  5.655473e-04 -6.511630e-19 -3.374899e-02   \n",
       "75%    5.501658e-01  2.608286e-01  2.181613e-01 -6.511630e-19  4.485684e-01   \n",
       "max    1.201366e+01  4.178875e+00  8.927989e+00  2.590784e+01  1.676119e+01   \n",
       "\n",
       "                U_d  prediction_1  prediction_6  prediction_12  prediction_24  \n",
       "count  6.742000e+03  6.742000e+03  6.742000e+03   6.742000e+03   6.742000e+03  \n",
       "mean   3.231701e-18 -1.655372e-17 -8.521810e-18   1.626966e-17  -1.630259e-18  \n",
       "std    1.000074e+00  1.000074e+00  1.000074e+00   1.000074e+00   1.000074e+00  \n",
       "min   -9.618483e+00 -6.588261e+00 -3.914840e+00  -4.549679e+00  -5.121136e+00  \n",
       "25%   -5.126873e-01 -5.532996e-01 -6.431330e-01  -6.474076e-01  -6.229991e-01  \n",
       "50%   -7.159847e-04 -6.326188e-03  3.432686e-02   3.232712e-03  -3.859763e-03  \n",
       "75%    5.112562e-01  5.502142e-01  6.441442e-01   6.676213e-01   6.328572e-01  \n",
       "max    6.845087e+00  1.201367e+01  4.956720e+00   3.922944e+00   4.019212e+00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = drop_duplicates(df)\n",
    "dataset = impute_missing(dataset)\n",
    "\n",
    "#select features we're going to use\n",
    "features = dataset[['ePower', 'DD', 'FF', 'N', 'Q', 'RG', 'T', 'U']]\n",
    "\n",
    "# the time horizons we're going to predict (in hours)\n",
    "horizons = [1, 6, 12, 24]\n",
    "\n",
    "features = first_order_difference(features, features.columns)\n",
    "features = derive_prediction_columns(features, 'FF', horizons)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled = scale_features(scaler, features)\n",
    "\n",
    "scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_train(data, features, predictions, sequence_length, split_percent=0.9):\n",
    "    \n",
    "    num_features = len(features)\n",
    "    num_predictions = len(predictions)\n",
    "    \n",
    "     # make sure prediction cols are at end\n",
    "    columns = features + predictions\n",
    "    \n",
    "    data = data[columns].values\n",
    "    \n",
    "    print(\"Using {} features to predict {} horizons\".format(num_features, num_predictions))\n",
    "    \n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length+1):\n",
    "        result.append(data[index:index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "    # shape (n_samples, sequence_length, num_features + num_predictions)\n",
    "    print(\"Shape of data: {}\".format(np.shape(result)))\n",
    "    \n",
    "    row = round(split_percent * result.shape[0])\n",
    "    train = result[:row, :]\n",
    "    \n",
    "    X_train = train[:, :, :-num_predictions]\n",
    "    y_train = train[:, -1, -num_predictions:]\n",
    "    X_test = result[row:, :, :-num_predictions]\n",
    "    y_test = result[row:, -1, -num_predictions:]\n",
    "    \n",
    "    print(\"Shape of X train: {}\".format(np.shape(X_train)))\n",
    "    print(\"Shape of y train: {}\".format(np.shape(y_train)))\n",
    "    print(\"Shape of X test: {}\".format(np.shape(X_test)))\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], num_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], num_features))\n",
    "    \n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], num_predictions))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0], num_predictions))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 features to predict 4 horizons\n",
      "Shape of data: (6695, 48, 12)\n",
      "Shape of X train: (6026, 48, 8)\n",
      "Shape of y train: (6026, 4)\n",
      "Shape of X test: (669, 48, 8)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 48\n",
    "\n",
    "prediction_cols = ['prediction_' + str(h) for h in horizons]\n",
    "feature_cols = ['ePower', 'DD', 'FF', 'N', 'Q', 'RG', 'T', 'U']\n",
    "\n",
    "X_train, y_train, X_test, y_test, row_split = prepare_test_train(\n",
    "    scaled,\n",
    "    feature_cols,\n",
    "    prediction_cols,\n",
    "    sequence_length,\n",
    "    split_percent = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#(-1 is because we only take the last y row in each sequence)\n",
    "sequence_offset = sequence_length  - 1\n",
    "\n",
    "# validate train\n",
    "inverse_scale = invert_all_prediction_scaled(scaler, y_train, scaled.columns, horizons)\n",
    "\n",
    "assert(mean_squared_error(\n",
    "    features[prediction_cols][sequence_offset:row_split+sequence_offset], \n",
    "    inverse_scale) < 1e-10)\n",
    "\n",
    "\n",
    "undiff_prediction = invert_all_prediction_differences(\n",
    "    inverse_scale, \n",
    "    features['FF'][sequence_offset:row_split+sequence_offset])\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    assert(mean_squared_error(\n",
    "        features['FF'][sequence_offset+horizon:row_split+sequence_offset+horizon], \n",
    "        undiff_prediction[:,i]) < 1e-10)\n",
    "\n",
    "    \n",
    "# validate test\n",
    "inverse_scale = invert_all_prediction_scaled(scaler, y_test, scaled.columns, horizons)\n",
    "\n",
    "assert(mean_squared_error(\n",
    "    features[prediction_cols][sequence_offset+row_split:], \n",
    "    inverse_scale) < 1e-10)\n",
    "\n",
    "undiff_prediction = invert_all_prediction_differences(\n",
    "    inverse_scale, \n",
    "    features['FF'][sequence_offset+row_split:])\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    assert(mean_squared_error(\n",
    "        features['FF'][sequence_offset+row_split+horizon:], \n",
    "        undiff_prediction[:-horizon,i]) < 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(\n",
    "            layers[1],\n",
    "            input_shape=(None, layers[0]),\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(layers[2], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(layers[3], return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(layers[4], activation=\"linear\"))\n",
    "    \n",
    "    model = multi_gpu_model(model, gpus=num_gpu)\n",
    "    model.compile(loss=\"mse\", optimizer='nadam')\n",
    "    \n",
    "    print(model.summary())\n",
    "          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "def run_network(X_train, y_train, X_test, layers, epochs, batch_size=512):\n",
    "    model = build_model(layers)\n",
    "    history = None\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs, \n",
    "            validation_split=0.1,\n",
    "            callbacks=[\n",
    "                TensorBoard(log_dir='/tmp/tensorboard', write_graph=True), PlotLossesKeras()\n",
    "                #EarlyStopping(monitor='val_loss', patience=5, mode='auto')\n",
    "            ])\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted\")\n",
    "    \n",
    "    predicted = model.predict(X_test)\n",
    "    \n",
    "    return model, predicted, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAE1CAYAAACcD1XPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5423/5423 [==============================] - 4s 663us/step - loss: 0.3994 - val_loss: 1.2677\n"
     ]
    }
   ],
   "source": [
    "model, predicted, history = run_network(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    layers=[X_train.shape[2], 20, 15, 20, y_train.shape[1]],\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
