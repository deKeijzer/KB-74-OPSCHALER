{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "mpl.style.use('default')\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    \"\"\"\n",
    "    Reduces memory footprint of the input dataframe.\n",
    "    Changes float64 columns to float32 dtype.\n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    memory_before = df.memory_usage(deep=False).sum() / 2**30 # convert bytes to GB\n",
    "\n",
    "    for column in tqdm(columns):\n",
    "        if df[column].dtype == 'float64':\n",
    "            df[column] = df[column].astype('float32')\n",
    "        \n",
    "    memory_after = df.memory_usage(deep=False).sum() / 2**30 # convert bytes to GB\n",
    "    print('Memory uasge reduced from %.3f GB to %.3f GB' % (memory_before, memory_after))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_corr_matrix(df, dwelling_id, annot):\n",
    "    \"\"\"\n",
    "    Pearson correlation coefficient matrix. \n",
    "    The Pearson correlation coefficient is a measure of the linear correlation between two variables.\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    \n",
    "    corr = df.corr()\n",
    "    mask = np.zeros_like(df.corr())\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    if annot:\n",
    "        fig, ax = plt.subplots(figsize=(18,18))\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    fig = sns.heatmap(corr, mask=mask, square=False, cmap='RdYlGn', annot=annot, ax=ax, \n",
    "                cbar_kws={'label':'Pearson correlation coefficient [-]'})\n",
    "\n",
    "    fig.set_title('Correlation matrix of dwelling ID: '+dwelling_id)\n",
    "    fig.tick_params(axis='x', rotation=90)\n",
    "    fig.tick_params(axis='y', rotation=0)\n",
    "\n",
    "    fig = fig.get_figure()\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    print('Saving heatmap')\n",
    "    #fig.savefig('//datc//opschaler//EDA//Pearson_corr//' + dwelling_id + '.png', dpi=300)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def resample_df(df, sample_rate, combine_all_dwellings=False):\n",
    "    \"\"\"\n",
    "    Resampled a (un)processed dataframe to the specified sample_rate.\n",
    "    Input is a (un)processed df.\n",
    "    Input df may also be multiple dwelling dfs combined.\n",
    "    Sample rate must be a string. \n",
    "    For example '1H', '1D', '60s'.\n",
    "    \n",
    "    Combine all dwellings: resamples the df and ignores the fact that there are unique dwellings.\n",
    "    \"\"\"\n",
    "    def resample_dwelling(df, sample_rate, dwelling_id):\n",
    "        df = df.resample(sample_rate).mean() # resample to rest by mean\n",
    "        df['dwelling'] = dwelling_id\n",
    "        return df\n",
    "        \n",
    "                      \n",
    "    resampled_dwellings = []\n",
    "    \n",
    "    if combine_all_dwellings: # Ignore dwelling_ids\n",
    "        df = df.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter'], axis=1) # Drop columns because they are meaningless when ignoring dwelling ids\n",
    "        resampled_df = resample_dwelling(df, sample_rate, 'All dwellings')\n",
    "        resampled_dwellings.append(resampled_df)\n",
    "    else:\n",
    "        dwellings = df['dwelling'].unique() # Get dwelling ids\n",
    "        for dwelling_id in tqdm(dwellings):\n",
    "            dwelling_df = df[df['dwelling'] == dwelling_id] # Get the data from only that dwelling_id\n",
    "            resampled_dwelling = resample_dwelling(dwelling_df, sample_rate, dwelling_id)\n",
    "            resampled_dwellings.append(resampled_dwelling)\n",
    "    \n",
    "    resampled_df = pd.concat(resampled_dwellings)\n",
    "    \n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 395.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.022 GB to 0.012 GB\n",
      "CPU times: user 483 ms, sys: 47.9 ms, total: 531 ms\n",
      "Wall time: 530 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('//datc//opschaler//combined_gas_smart_weather_dfs//processed//all_dwellings_combined_hour.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "df = df.set_index(['datetime'])\n",
    "df = reduce_memory(df) # converts float64 to float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 116.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f32b8b4b908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day = resample_df(df,'1M')\n",
    "sns.heatmap(day.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on daily mean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig = create_corr_matrix(day, 'all dwellings', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "def datetime_layout():\n",
    "    plt.xticks(rotation=45)\n",
    "    #plt.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "x = day.index\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.plot(x, day['Q'], '.', color='r', linewidth=0.3)\n",
    "#plt.xlabel('Date [-]')\n",
    "plt.ylabel('Global Radiation [J/m$^2$]')\n",
    "datetime_layout()\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "plt.plot(x, day['T'], '.', color='r', linewidth=0.3)\n",
    "#plt.xlabel('Date [-]')\n",
    "plt.ylabel('Temperature [°C]')\n",
    "datetime_layout()\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "plt.plot(x, day['ePower'], '.', color='r', linewidth=0.3)\n",
    "#plt.xlabel('Date [-]')\n",
    "plt.ylabel('ePower [kWh]')\n",
    "datetime_layout()\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.plot(x, day['gasPower'], '.', color='r', linewidth=0.3)\n",
    "#plt.xlabel('Date [-]')\n",
    "plt.ylabel('gasPower [m$^3$]')\n",
    "datetime_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "datetime_layout()\n",
    "\n",
    "ax.plot(x, day['T'], 'b.', linewidth=0.5, label='Temperature')\n",
    "ax.set_ylabel('Temperature [°C]')\n",
    "ax.legend(loc='lower left', bbox_to_anchor= (0.0, 1.01), borderaxespad=0, frameon=False) # Put legend on custom location\n",
    "# more legend info: https://jdhao.github.io/2018/01/23/matplotlib-legend-outside-of-axes/\n",
    "\n",
    "ax = ax.twinx() \n",
    "ax.plot(x, day.gasPower, 'r.', linewidth=0.5, label='gasPower')\n",
    "ax.set_ylabel('gasPower [m$^3$ per hour]')\n",
    "\n",
    "ax.legend(loc='lower left', bbox_to_anchor= (0.3, 1.01), borderaxespad=0, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "datetime_layout()\n",
    "\n",
    "ax.plot(x, day['Q'], 'b.', linewidth=0.5, label='Global radiation')\n",
    "ax.set_ylabel('Global Radiation [J/m$^2$]')\n",
    "ax.legend(loc='lower left', bbox_to_anchor= (0.0, 1.01), borderaxespad=0, frameon=False) # Put legend on custom location\n",
    "# more legend info: https://jdhao.github.io/2018/01/23/matplotlib-legend-outside-of-axes/\n",
    "\n",
    "ax = ax.twinx() \n",
    "ax.plot(x, day.gasPower, 'r.', linewidth=0.5, label='gasPower')\n",
    "ax.set_ylabel('gasPower [m$^3$ per hour]')\n",
    "\n",
    "ax.legend(loc='lower left', bbox_to_anchor= (0.3, 1.01), borderaxespad=0, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(day['T'], day['gasPower'], '.', color='r', linewidth=0.3)\n",
    "plt.ylabel('gasPower [m$^3$ per hour]')\n",
    "plt.xlabel('Temperature [°C]')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(day['Q'], day['T'], '.', color='r', linewidth=0.3)\n",
    "plt.ylabel('gasPower [m$^3$ per hour]')\n",
    "plt.xlabel('Global Radiation [J/m$^2$]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=\"T\", y=\"gasPower\", data=day, kind=\"reg\", color='r')\n",
    "sns.plt.ylabel('gasPower [m$^3$ per hour]')\n",
    "sns.plt.xlabel('Temperature [°C]')\n",
    "sns.plt.tight_layout()\n",
    "sns.plt.title('1 Day mean of all dwellings', y=1.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x=\"Q\", y=\"gasPower\", data=day, kind=\"reg\", color='r')\n",
    "sns.plt.ylabel('gasPower [m$^3$ per hour]')\n",
    "sns.plt.xlabel('Global Radiation [J/m$^2$]')\n",
    "sns.plt.tight_layout()\n",
    "sns.plt.title('1 Day mean of all dwellings', y=1.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(day['T'], day['Q'], day['gasPower'], '.', color='r')\n",
    "\n",
    "ax.set_xlabel('T')\n",
    "ax.set_ylabel('Q')\n",
    "ax.set_zlabel('gasPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_trisurf(day['T'], day['Q'], day['gasPower'], cmap=plt.cm.viridis, linewidth=0.2, antialiased=True)\n",
    "\n",
    "ax.set_xlabel('T')\n",
    "ax.set_ylabel('Q')\n",
    "ax.set_zlabel('gasPower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable linear regression: predict gasPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Nobody turns on their heating when T > 19?, so deselect this data\n",
    "data = day[day['T'] < 19]\n",
    "\n",
    "\n",
    "\n",
    "#X = filtered.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter', 'WW', 'VV', 'P', 'DR', 'SQ', 'TD', 'T10', 'FX'], axis=1)\n",
    "X = data[['T', 'Q']]\n",
    "print('X columns: %s' % list(X.columns))\n",
    "y = data['gasPower']\n",
    "\n",
    "X = np.array(X).reshape(-1,len(X.columns)) # Reshape because sklearn wants you to\n",
    "y = np.array(y).reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(data['T'], data['Q'], data['gasPower'], '.', color='r')\n",
    "\n",
    "ax.set_xlabel('T')\n",
    "ax.set_ylabel('Q')\n",
    "ax.set_zlabel('gasPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_trisurf(data['T'], data['Q'], data['gasPower'], cmap=plt.cm.viridis, linewidth=0.2, antialiased=True)\n",
    "\n",
    "ax.set_xlabel('T')\n",
    "ax.set_ylabel('Q')\n",
    "ax.set_zlabel('gasPower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable linear regression: predict gasPower with more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = day[day['T'] < 19]\n",
    "\n",
    "X = data.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter','gasPower', 'WW', 'VV', 'P', 'DR', 'SQ', 'TD', 'T10', 'FX'], axis=1)\n",
    "print('X columns: %s' % list(X.columns))\n",
    "y = data['gasPower']\n",
    "\n",
    "X = np.array(X).reshape(-1,len(X.columns)) # Reshape because sklearn wants you to\n",
    "y = np.array(y).reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite high...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable linear regression: predict ePower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = day[day['T'] < 19]\n",
    "\n",
    "X = data.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter','ePower','ePowerReturn', 'WW', 'VV', 'P', 'DR', 'SQ', 'TD', 'T10', 'FX'], axis=1)\n",
    "print('X columns: %s' % list(X.columns))\n",
    "y = data['ePower']\n",
    "\n",
    "X = np.array(X).reshape(-1,len(X.columns)) # Reshape because sklearn wants you to\n",
    "y = np.array(y).reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "## Initialize tensorflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup multi GPU usage\n",
    "\n",
    "Example usage:\n",
    "model = Sequential()\n",
    "...\n",
    "multi_model = multi_gpu_model(model, gpus=num_gpu)\n",
    "multi_model.fit()\n",
    "\n",
    "About memory usage:\n",
    "https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# IMPORTANT: Tells tf to not occupy a specific amount of memory\n",
    "from keras.backend.tensorflow_backend import set_session  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
    "sess = tf.Session(config=config)  \n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras.\n",
    "\n",
    "\n",
    "# getting the number of GPUs \n",
    "def get_available_gpus():\n",
    "   local_device_protos = device_lib.list_local_devices()\n",
    "   return [x.name for x in local_device_protos if x.device_type    == 'GPU']\n",
    "num_gpu = len(get_available_gpus())\n",
    "print('Amount of GPUs available: %s' % num_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "data = day[day['T'] < 19]\n",
    "epower = data.iloc[:,0].values.reshape(-1,1) # select and reshape gasPower\n",
    "\n",
    "# scale the data\n",
    "#scaler = MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "epower = scaler.fit_transform(epower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictors from targets\n",
    "X = data.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter','gasPower','ePowerReturn', 'WW', 'VV', 'P', 'DR', 'SQ', 'TD', 'T10', 'FX'], axis=1)\n",
    "print('X columns: %s' % list(X.columns))\n",
    "y = data[['gasPower']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "#X_train = preprocessing.scale(X_train)\n",
    "#X_test = preprocessing.scale(X_test)\n",
    "#y_train = np.array(y_train)\n",
    "#y_test = np.array(y_test)\n",
    "\n",
    "#y_train = preprocessing.scale(y_train) # No need to scale the y's ?\n",
    "#y_test = preprocessing.scale(y_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('')\n",
    "print('X_train variance', X_train.var())\n",
    "print('y_train variance', y_train.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, input_shape=(8,), kernel_initializer='normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16*16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16*16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "#model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = multi_gpu_model(model, gpus=num_gpu)\n",
    "\n",
    "# compiling the sequential model\n",
    "multi_model.compile(loss='mean_squared_error', metrics=['mse'], optimizer='adam')\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=100)\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "# training the model and saving metrics in history\n",
    "multi_model.fit(X_train, y_train, batch_size=int(len(X_train)), epochs=100, verbose=2, validation_data=(X_test, y_test), callbacks=[early_stopping_monitor, PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret mean squared error:  \n",
    "`The MSE is a measure of the quality of an estimator—it is always non-negative, and values closer to zero are better.`  \n",
    "https://en.wikipedia.org/wiki/Mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras on higher resolution data\n",
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = df\n",
    "data = data.set_index(['datetime'])\n",
    "data = data.resample('H').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create columns with time information. \n",
    "The idea is that the neural network will start taking time into account also.\n",
    "\"\"\"\n",
    "data['hour'] = data.index.hour\n",
    "#data['minute'] = data.index.minute\n",
    "#data['second'] = data.index.second\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "epower = data.iloc[:,0].values.reshape(-1,1) # select and reshape gasPower\n",
    "\n",
    "# scale the data\n",
    "#scaler = MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "epower = scaler.fit_transform(epower)\n",
    "\n",
    "# Split predictors from targets\n",
    "X = data.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter','gasPower','ePowerReturn', 'WW', 'VV', 'P', 'DR', 'SQ', 'TD', 'T10', 'FX'], axis=1)\n",
    "print('X columns: %s' % list(X.columns))\n",
    "y = data[['gasPower']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "#X_train = preprocessing.scale(X_train)\n",
    "#X_test = preprocessing.scale(X_test)\n",
    "#y_train = np.array(y_train)\n",
    "#y_test = np.array(y_test)\n",
    "\n",
    "#y_train = preprocessing.scale(y_train) # No need to scale the y's ?\n",
    "#y_test = preprocessing.scale(y_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('')\n",
    "print('X_train variance', X_train.var())\n",
    "print('y_train variance', y_train.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9, input_shape=(9,), kernel_initializer='normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16*16, kernel_initializer='normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "#model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "multi_model = multi_gpu_model(model, gpus=num_gpu)\n",
    "\n",
    "# compiling the sequential model\n",
    "multi_model.compile(loss='mean_squared_error', metrics=['mse'], optimizer='Nadam')\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=5000)\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "# training the model and saving metrics in history\n",
    "multi_model.fit(X_train, y_train, batch_size=int(len(X_train)/10), epochs=1000, verbose=2, validation_data=(X_test, y_test), callbacks=[early_stopping_monitor, PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher resolution will give worse results (But why? The hour column is there...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same, but to predict energy usage\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "epower = data.iloc[:,0].values.reshape(-1,1) # select and reshape gasPower\n",
    "\n",
    "# scale the data\n",
    "#scaler = MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "epower = scaler.fit_transform(epower)\n",
    "\n",
    "# Split predictors from targets\n",
    "X = data.drop(['eMeter', 'eMeterReturn', 'eMeterLow', 'eMeterLowReturn', 'gasMeter', 'ePower','ePowerReturn', 'WW', 'VV', 'P', 'DR', 'SQ', 'TD', 'T10', 'FX'], axis=1)\n",
    "print('X columns: %s' % list(X.columns))\n",
    "y = data[['ePower']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "#X_train = preprocessing.scale(X_train)\n",
    "#X_test = preprocessing.scale(X_test)\n",
    "#y_train = np.array(y_train)\n",
    "#y_test = np.array(y_test)\n",
    "\n",
    "#y_train = preprocessing.scale(y_train) # No need to scale the y's ?\n",
    "#y_test = preprocessing.scale(y_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('')\n",
    "print('X_train variance', X_train.var())\n",
    "print('y_train variance', y_train.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9, input_shape=(9,), kernel_initializer='normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16*16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "#model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "multi_model = multi_gpu_model(model, gpus=num_gpu)\n",
    "\n",
    "# compiling the sequential model\n",
    "multi_model.compile(loss='mean_squared_error', metrics=['mse'], optimizer='adam')\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=100)\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "# training the model and saving metrics in history\n",
    "multi_model.fit(X_train, y_train, batch_size=int(len(X_train)/10), epochs=50, verbose=2, validation_data=(X_test, y_test), callbacks=[early_stopping_monitor, PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
