{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shifr+F9 (Debug first, then plots will appear in SciView)\n",
    "\n",
    "TODO: add legend to plot_nans\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('default')\n",
    "\n",
    "\n",
    "def clean_datetime(df):\n",
    "    \"\"\"\n",
    "    TODO: Speed up the function\n",
    "    Input should be a df with a column called 'datetime'.\n",
    "    This function checks wether a row in the df.datetime column can be parsed to a Pandas datetime object,\n",
    "    by trying pd.to_datetime() on it.\n",
    "    If it fails it will replace that row with np.nan().\n",
    "    Finally this function will return the df with the NaN rows dropped.\n",
    "    It only drops the row if the datetime column contains a NaN.\n",
    "\n",
    "    :param df: Pandas DataFrame containing a datetime column called 'datetime'.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            pd.to_datetime(df.datetime[i])\n",
    "        except ValueError:\n",
    "            print('-----')\n",
    "            print('ValueError at index = %s' % i)\n",
    "            print(df.datetime[i])\n",
    "            df.datetime = df.datetime.replace(df.datetime[i], np.nan)\n",
    "    df = df.dropna(subset=['datetime'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_prepare_smart_gas(file_path):\n",
    "    \"\"\"\n",
    "    Input is a dwelling_id.csv file.\n",
    "    Output are cleaned & prepared dataframes (smart, gas).\n",
    "\n",
    "    :param file_path: path to 'dwelling_id.csv' file\n",
    "    :return: Smart and gas Pandas DataFrames\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, delimiter=';', header=0)\n",
    "    df = df.rename(index=str, columns={'Timestamp': 'datetime', 'gasTimestamp': 'datetime'})\n",
    "\n",
    "    smart = df.iloc[:, :7]\n",
    "    gas = df.iloc[:, 7:]\n",
    "\n",
    "    try:\n",
    "        smart['datetime'] = pd.to_datetime(smart['datetime'])\n",
    "        gas['datetime'] = pd.to_datetime(gas['datetime'])\n",
    "    except:\n",
    "        print('datetime column contains non-datetime values')\n",
    "        smart = clean_datetime(smart)\n",
    "        gas = clean_datetime(gas)\n",
    "        smart['datetime'] = pd.to_datetime(smart['datetime'])\n",
    "        gas['datetime'] = pd.to_datetime(gas['datetime'])\n",
    "\n",
    "    smart = smart.set_index(['datetime'])\n",
    "    gas = gas.set_index(['datetime'])\n",
    "\n",
    "    smart = smart.astype(dtype='float32')\n",
    "    gas = gas.astype(dtype='float32')\n",
    "\n",
    "    return smart, gas\n",
    "\n",
    "\n",
    "def df_nan_checker(df, threshold_percentage):\n",
    "    \"\"\"\n",
    "    TODO: Parellalize, as in one column per core/worker?\n",
    "    Checks each column in the input dataframe for NaNs.\n",
    "    Outputs the amount of NaNs behind each other, including the start and stop index, per column as a sublist.\n",
    "    For example when the dataframe has three columns.\n",
    "    Output is in the form of:\n",
    "    [[column_one_info], [column_two_info], [column_three_info]]\n",
    "    With the column_..._info being in the form of:\n",
    "    [start_index, stop_index, amount_of_NaNs]\n",
    "\n",
    "    :param df: Pandas DataFrame\n",
    "    :param threshold_percentage: Filter output based on NaN streaks being larger than x % of the total length of the dataframe.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    columns = df.columns\n",
    "    df = df.isnull()\n",
    "    output = []\n",
    "    length = len(columns)\n",
    "\n",
    "    for i in range(length):\n",
    "        #print('At iteration %s of %s' % (i, length))\n",
    "        column_name = columns[i]\n",
    "        column_info = []\n",
    "        temp = []\n",
    "        x = False\n",
    "\n",
    "        for j, value in enumerate(df[column_name]):\n",
    "            if x == False and value == True:\n",
    "                temp.append(df.index[j])\n",
    "                x = True\n",
    "            elif x == True and value == True:\n",
    "                temp.append(df.index[j])\n",
    "            elif x == True and value == False:\n",
    "                column_info.append(temp)\n",
    "                temp = []\n",
    "                x = False\n",
    "\n",
    "        lengths = []\n",
    "\n",
    "        for array in column_info:\n",
    "            lengths.append([array[0], array[-1], len(array)])\n",
    "\n",
    "        output.append(lengths)\n",
    "\n",
    "    # Convert df_info to a readable dataframe instead of list\n",
    "\n",
    "    \"\"\"\n",
    "    Row per column from the 'output' list\n",
    "    Columns: start-index, stop-index, NaN streak\n",
    "    \"\"\"\n",
    "\n",
    "    df_info = pd.DataFrame(columns=['Column name', 'Start index', 'Stop index', 'Amount of NaNs'])\n",
    "    length = len(output)\n",
    "    column_names = []\n",
    "    starts = []\n",
    "    stops = []\n",
    "    amounts = []\n",
    "\n",
    "    for column in range(length):\n",
    "        #print('At iteration %s of %s' % (column, length))\n",
    "        for i in range(len(output[column])):\n",
    "            column_names.append(df.columns[column])\n",
    "            starts.append(output[column][i][0])\n",
    "            stops.append(output[column][i][1])\n",
    "            amounts.append(output[column][i][2])\n",
    "\n",
    "    print('Appending NaN info to df')\n",
    "    # Convert list to pd series\n",
    "    column_names = pd.Series(column_names)\n",
    "    starts = pd.Series(starts)\n",
    "    stops = pd.Series(stops)\n",
    "    amounts = pd.Series(amounts)\n",
    "    # Append pd series to a column\n",
    "    df_info['Column name'] = column_names.values\n",
    "    df_info['Start index'] = starts.values\n",
    "    df_info['Stop index'] = stops.values\n",
    "    df_info['Amount of NaNs'] = amounts.values\n",
    "\n",
    "    percentage = (df_info['Amount of NaNs'] / len(df)) * 100\n",
    "    df_info.drop(df_info[percentage < threshold_percentage].index, inplace=True)\n",
    "\n",
    "    return df_info\n",
    "\n",
    "\n",
    "def smart_gas_nan_checker(smart, gas, weather, dwelling_id):\n",
    "    \"\"\"\n",
    "    Resamples the (smart, gas) dfs to 10s.\n",
    "    Also calculates gasPower.\n",
    "    Returns (smart_resampled, gas_resampled)\n",
    "\n",
    "    Original sample rates are as follows:\n",
    "    smart: 10 seconds\n",
    "    gas: 1 hour\n",
    "    weather: 10 minutes\n",
    "\n",
    "    :param smart: Pandas DataFrame\n",
    "    :param gas: Pandas DataFrame\n",
    "    :param weather: Pandas DataFrame\n",
    "    :param dwelling_id: String\n",
    "    :return: smart_resampled, gas_resampled as a Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    print('Resampling smart, gas, weather')\n",
    "    # For more resampling info see: https://pandas.pydata.org/pandas-docs/stable/api.html#id41\n",
    "    # Makes missing gaps appear as NaN, these are the general raw dataframes to work with\n",
    "    smart_10s = smart.resample('10s').mean()\n",
    "    gas_h = gas.resample('H').mean()\n",
    "    weather_10min = weather.resample('10min').mean()\n",
    "\n",
    "    \"\"\"\n",
    "    Create a dataframe with a 1 hour sample rate\n",
    "    \"\"\"\n",
    "    gas_h['gasPower'] = gas_h['gasMeter'].diff()  # Calculate gasPower column\n",
    "    gas_h['gasPower'][0] = gas_h['gasPower'][1]  # Replace 1st entry (NaN) with 2nd entry\n",
    "\n",
    "    smart_h = smart_10s.resample('H').mean()  # Down sample smart\n",
    "    weather_h = weather_10min.resample('H').mean()  # Down sample weather\n",
    "\n",
    "    # Combine gas, smart, weather\n",
    "    df_hour = pd.merge(smart_h, gas_h, left_index=True, right_index=True)\n",
    "    df_hour = pd.merge(df_hour, weather_h, left_index=True, right_index=True)\n",
    "\n",
    "    \"\"\"\n",
    "    Create smartmeter dataframe with a 10s sample rate\n",
    "    \"\"\"\n",
    "    gas_10s = gas_h.resample('10s').ffill()  # Up sample gas to 10s\n",
    "    # Calculate gasPower column, is this rhe right way? Or should we ffill it?\n",
    "    # Currently this code makes it so there is one gasPower value per hour, we could ffill this also?\n",
    "    gas_10s['gasPower'] = gas_10s['gasMeter'].diff()\n",
    "    gas_10s['gasPower'][0] = gas_10s['gasPower'][1]  # Replace 1st entry (NaN) with 2nd entry\n",
    "\n",
    "    weather_10s = weather_10min.resample('10s').ffill()  # forward fill because the raw data is the 10 minute mean\n",
    "\n",
    "    # Combine gas, smart, weather\n",
    "    df_10s = pd.merge(smart_10s, gas_10s, left_index=True, right_index=True)\n",
    "    df_10s = pd.merge(df_10s, weather_10s, left_index=True, right_index=True)\n",
    "\n",
    "    \"\"\"\n",
    "    Do NaN analysis on the 10s and hour sample rate dataframes\n",
    "    \"\"\"\n",
    "    print('Length of combined df_10s: %s' % len(df_10s))\n",
    "    print('df_nan_fig_10s')\n",
    "    df_nan_fig_10s = plot_nans(df_10s, dwelling_id+' 10s sample rate')\n",
    "    print('df_nan_table_10s')\n",
    "    df_nan_table_10s = df_nan_checker(df_10s, 0)\n",
    "\n",
    "    print('Length of combined df_hour: %s' % len(df_hour))\n",
    "    print('df_nan_fig_hour')\n",
    "    df_nan_fig_hour = plot_nans(df_hour, dwelling_id+' 1 hour sample rate')\n",
    "    print('df_nan_table_hour')\n",
    "    df_nan_table_hour = df_nan_checker(df_hour, 0)\n",
    "\n",
    "    return df_10s, df_hour, df_nan_table_10s, df_nan_table_hour, df_nan_fig_hour, df_nan_fig_10s\n",
    "\n",
    "\n",
    "def drop_nan_streaks_above_threshold(df, df_nan_table, thresholds):\n",
    "    \"\"\"\n",
    "    Drops NaN streaks from the df when they are larger then the threshold value.\n",
    "    This function also inputs df_nan_table because it already has been made in the smart_gas_nan_checker.\n",
    "    :param df: Pandas DataDrame to process NaNs off\n",
    "    :param df_nan_table: NaN info Pandas DataFrame of the input df\n",
    "    :param thresholds: Dictionary {'column_name':column_threshold}, column_threshold has to be an integer.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Check for NaN streaks > threshold and drop them from the df\n",
    "    length = len(df_nan_table['Amount of NaNs'])\n",
    "    print('df_nan_table length: %s' % length)\n",
    "\n",
    "    indices_to_drop = []\n",
    "    for i, amount in enumerate(df_nan_table['Amount of NaNs']):\n",
    "        selected_column = df_nan_table['Column name'][i]\n",
    "        try:\n",
    "            if amount > thresholds[selected_column]:\n",
    "                start_index = (df_nan_table['Start index'][i])\n",
    "                stop_index = (df_nan_table['Stop index'][i])\n",
    "                indices = df[start_index:stop_index].index\n",
    "                print('Enumeration %s of %s | From \\t %s \\t to \\t %s | column %s | NaN streak length: %s'\n",
    "                      % (i, length, start_index, stop_index, selected_column, (len(indices))))\n",
    "                try:\n",
    "                    indices_to_drop += indices\n",
    "                except:\n",
    "                    print('Could not add indices to indices_to_drop list')\n",
    "            else:\n",
    "                #print('amount < threshold')\n",
    "                pass\n",
    "        except:\n",
    "            #print('No threshold detected for %s' % selected_column)\n",
    "            pass\n",
    "\n",
    "    print('Dropping NaN streaks > threshold')\n",
    "    l1 = len(df)\n",
    "    df = df.drop(indices_to_drop)\n",
    "    l2 = len(df)\n",
    "    print('Removed %s rows' % (l1-l2))\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_nans(df, dwelling_id):\n",
    "    \"\"\"\n",
    "    Create a heatmap of the NaNs in the input DataFrame.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param dwelling_id: String\n",
    "    :return: Seaborn heatmap as a Figure\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    df = df.isnull()\n",
    "    # Downsample to make all data visible\n",
    "    df = df.resample('1T').sum()  # Downsample to make small NaNs visible\n",
    "    df = df.apply(lambda x: x > 0, 1)  # Replace values >0 with 1\n",
    "\n",
    "    # Reindex datetimes\n",
    "    # https://stackoverflow.com/questions/41046630/set-time-formatting-on-a-datetime-index-when-plotting-pandas-series\n",
    "    try:\n",
    "        df.index = df.index.to_period('D')\n",
    "    except:\n",
    "        print('plot_nans could not set df.index.to_period')\n",
    "\n",
    "    # Plot heatmap\n",
    "    n = int(len(df)*0.1)  # Choose amount of yticklabels to show\n",
    "\n",
    "    try:\n",
    "        fig = sns.heatmap(df, cmap='Reds', square=False, vmin=0, cbar=False, yticklabels=n*2, cbar_kws={})\n",
    "    except TypeError:\n",
    "        print('plot_nans ValueError')\n",
    "        fig = sns.heatmap(df, cmap='Reds', square=False, vmin=0, cbar=False, cbar_kws={})\n",
    "\n",
    "    # Set cbar ticks manually\n",
    "    #cbar = fig.collections[0].colorbar\n",
    "    #cbar.set_ticks([0, 1])\n",
    "    #cbar.set_ticklabels(['Not NaN', 'NaN'])\n",
    "\n",
    "    # Correct layout\n",
    "    fig.invert_yaxis()\n",
    "    fig.tick_params(axis='x', rotation=90)\n",
    "    fig.tick_params(axis='y', rotation=0)\n",
    "    fig.set(xlabel='Column [-]', ylabel='Index [-]')\n",
    "    plt.title('Dwelling ID: '+dwelling_id)\n",
    "\n",
    "    fig = fig.get_figure()\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    print('Saving heatmap')\n",
    "    fig.savefig('//datc//opschaler//nan_information//figures//' + dwelling_id + '.png', dpi=1200)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def save_df_processed(df, dwelling_id):\n",
    "    \"\"\"\n",
    "    Save interpolated dataframe.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param dwelling_id: String\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//processed//'\n",
    "    df.to_csv(dir + dwelling_id + '.csv', sep='\\t', index=True)\n",
    "    print('Saved processed df: %s' % dwelling_id)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_df_unprocessed(df, dwelling_id):\n",
    "    \"\"\"\n",
    "    Save unprocessed dataframe.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param dwelling_id: String\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df.to_csv(dir + dwelling_id + '.csv', sep='\\t', index=True)\n",
    "    print('Saved not unprocessed df: %s' % dwelling_id)\n",
    "    return\n",
    "\n",
    "\n",
    "def dwelling_information (smart_gas_weather_resampled_combined, df_nan_table):\n",
    "    # create dataframe to store all information from the different files\n",
    "    df_dwelling_information = pd.DataFrame(columns={'Dwelling ID', 'file size [MB]', 'initial date', 'final date',\n",
    "                                                    'days', 'total amount of NaNs', 'largest max consecutive NaNs',\n",
    "                                                    'second largest max consecutive NaNs',\n",
    "                                                    'third_largest_max_consecutive_NaNs'})\n",
    "\n",
    "    # order of column names changed for some reason, line(below) fixes this, although ugly\n",
    "    df_dwelling_information = df_dwelling_information[['Dwelling ID', 'file size [MB]', 'initial date', 'final date',\n",
    "                                                       'days', 'total amount of NaNs', 'largest max consecutive NaNs',\n",
    "                                                       'second largest max consecutive NaNs',\n",
    "                                                       'third_largest_max_consecutive_NaNs']]\n",
    "\n",
    "    # smart needs to be replaced with name of df that is read in (raw, combined)\n",
    "    df_dwelling_information.loc[len(df_nan_table.index)] = [dwelling_id,\n",
    "                                                 smart_gas_weather_resampled_combined.memory_usage(index=True).sum()/1000000,\n",
    "                                                 smart_gas_weather_resampled_combined.index[0],\n",
    "                                                 smart_gas_weather_resampled_combined.index[-1],\n",
    "                                             smart_gas_weather_resampled_combined.index[-1] - smart_gas_weather_resampled_combined.index[0],\n",
    "                                             df_nan_table['Amount of NaNs'].sum(),\n",
    "                                                 df_nan_table['Amount of NaNs'].nlargest(1),\n",
    "                                             df_nan_table['Amount of NaNs'].nlargest(2),\n",
    "                                                 df_nan_table['Amount of NaNs'].nlargest(3)]\n",
    "    return df_dwelling_information\n",
    "\n",
    "\n",
    "def read_weather_data():\n",
    "    \"\"\"\n",
    "    Reads in the weather Pandas DataFrame.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Check if UTC to gmt+1 conversion is being handled correctly\n",
    "    weather = pd.read_csv('//datc//opschaler//weather_data//knmi_10_min_raw_data//output//df_combined_uncleaned.csv',\n",
    "                          delimiter='\\t', comment='#',\n",
    "                          parse_dates=['datetime'])\n",
    "    weather = weather.set_index(['datetime'])\n",
    "    return weather\n",
    "\n",
    "\n",
    "def smartmeter_data():\n",
    "    \"\"\"\n",
    "    Reads in the file paths and dwelling id's of the smartmeter data.\n",
    "    :return: file_paths, dwelling_ids, both as lists.\n",
    "    \"\"\"\n",
    "    path = '/datc/opschaler/smartmeter_data'\n",
    "    file_paths = np.array(glob.glob(path + \"/*.csv\"))\n",
    "\n",
    "    print('Detected %s smartmeter_data files.' % len(file_paths))\n",
    "    dwelling_ids = np.array(list((map(lambda x: x[-15:-4], file_paths))))\n",
    "\n",
    "    return file_paths, dwelling_ids\n",
    "\n",
    "\n",
    "def process_dfs(df_10s, df_hour):\n",
    "    \"\"\"\n",
    "    Forward fill all weather data.\n",
    "    Interpolate: smart & gas data, except for ePower, ePowerReturn and gasPower.\n",
    "    ePower, ePowerReturn and gasPower might still contains NaNs.\n",
    "    These can be dropped after reading in the processed df, if required.\n",
    "\n",
    "    :param df_10s: Pandas DataFrame\n",
    "    :param df_hour:  Pandas DataFrame\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    columns_to_ffill = ['DD', 'DR', 'FF', 'FX', 'N', 'P', 'Q', 'RG', 'SQ', 'T', 'T10', 'TD', 'U', 'VV', 'WW']\n",
    "    columns_to_interpolate = ['eMeter', 'gasMeter']\n",
    "\n",
    "    print('Processing df_10s')\n",
    "    df_10s[columns_to_ffill] = df_10s[columns_to_ffill].fillna(method='ffill')\n",
    "    df_10s[columns_to_interpolate] = df_10s[columns_to_interpolate].interpolate(method='time')\n",
    "    df_10s_processed = df_10s\n",
    "    print('Amount of NaNs left in df_10s_processed: %s' % df_10s_processed.isnull().sum().sum())\n",
    "\n",
    "    print('Processing df_hour')\n",
    "    df_hour[columns_to_ffill] = df_hour[columns_to_ffill].fillna(method='ffill')\n",
    "    df_hour[columns_to_interpolate] = df_hour[columns_to_interpolate].interpolate(method='time')\n",
    "    df_hour_processed = df_hour\n",
    "    print('Amount of NaNs left in df_hour_processed: %s' % df_hour_processed.isnull().sum().sum())\n",
    "\n",
    "    return df_10s_processed, df_hour_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the main loop\n",
    "t1 = time.time()\n",
    "\n",
    "print('Reading in weather data')\n",
    "weather = read_weather_data()\n",
    "file_paths, dwelling_ids = smartmeter_data()\n",
    "\n",
    "print(dwelling_ids)\n",
    "\n",
    "file_paths = file_paths[0:1]\n",
    "dwelling_ids = dwelling_ids[0:1]\n",
    "\n",
    "\"\"\"\n",
    "index 49 is the 'export_P01S01W0000.csv' test dataframe\n",
    "smart/gasMeter contains a NaN streak of 4 NaNs, this is 28.6 % of the total length.\n",
    "N=27:28 is the smallest test df\n",
    "daan 21:22\n",
    "\"\"\"\n",
    "for N in range(len(file_paths)):\n",
    "    t2 = time.time()\n",
    "    print('---------- N=%s ----------' % N)\n",
    "\n",
    "    file_path = file_paths[N]\n",
    "    dwelling_id = dwelling_ids[N]\n",
    "    print('Selected dwelling_id: '+dwelling_ids[N])\n",
    "\n",
    "    print('----- clean_prepare_smart_gas -----')\n",
    "    # Read in raw smartmeter dataframe, split them into smart, gas df\n",
    "    smart, gas = clean_prepare_smart_gas(file_path)\n",
    "\n",
    "    print('----- smart_gas_nan_checker -----')\n",
    "    # Resample dataframes (using mean()), then upsample to 10s using ffill and output nan_info\n",
    "    df_10s, df_hour, df_nan_table_10s, df_nan_table_hour, df_nan_fig_hhour, df_nan_fig_10s = smart_gas_nan_checker(smart, gas, weather, dwelling_id)\n",
    "\n",
    "    print('----- save_df_unprocessed -----')\n",
    "    save_df_unprocessed(df_10s, dwelling_id+'_10s')\n",
    "    save_df_unprocessed(df_hour, dwelling_id+'_hour')\n",
    "\n",
    "    print('----- df_nan_table.to_csv -----')\n",
    "    df_nan_table_10s.to_csv('//datc//opschaler//nan_information//'+dwelling_id+'_10s.csv', sep='\\t')\n",
    "    df_nan_table_hour.to_csv('//datc//opschaler//nan_information//' + dwelling_id + '_hour.csv', sep='\\t')\n",
    "\n",
    "    print('----- smart_gas_resampled_combined NaNs -----')\n",
    "    print('df_10s NaNs: %s' % df_10s.isnull().sum())\n",
    "    print('df_hour NaNs: %s' % df_10s.isnull().sum())\n",
    "\n",
    "    \"\"\"\n",
    "    Original sample rate:\n",
    "    Electricity: 10 seconds\n",
    "    gas: 1 hour\n",
    "    weather: 10 minutes\n",
    "    \n",
    "    So for example setting the thresholds for the 10s dataframe:\n",
    "    \n",
    "    eMeter   6 -> equals a 60 seconds gap\n",
    "    ePower   6 -> equals a 60 seconds gap\n",
    "    gasMeter 36 -> equals a 1 hour gap\n",
    "    T       36 -> equals a 1 hour gap\n",
    "    Q       18 -> equals a 30 minute gap \n",
    "    \"\"\"\n",
    "    print('----- drop_nan_streaks_above_threshold -----')\n",
    "    thresholds_10s = {'eMeter': 6, 'ePower': 6, 'gasMeter': 72, 'T': 36, 'Q': 18}\n",
    "    df_10s_partly_processed = drop_nan_streaks_above_threshold(df_10s, df_nan_table_10s, thresholds_10s)\n",
    "\n",
    "    thresholds_hour = {'eMeter': 2, 'ePower': 2, 'gasMeter': 2, 'T': 1, 'Q': 1}\n",
    "    df_hour_partly_processed = drop_nan_streaks_above_threshold(df_hour, df_nan_table_hour, thresholds_hour)\n",
    "\n",
    "    print('----- dwelling_information -----')\n",
    "    dwelling_info_df_10s = dwelling_information(df_10s, df_nan_table_10s)\n",
    "    dwelling_info_df_10s.to_csv('//datc//opschaler//dwelling_information//'+dwelling_id+'_10s.csv', sep='\\t')\n",
    "\n",
    "    dwelling_info_df_hour = dwelling_information(df_hour, df_nan_table_hour)\n",
    "    dwelling_info_df_hour.to_csv('//datc//opschaler//dwelling_information//'+dwelling_id+'_hour.csv', sep='\\t')\n",
    "\n",
    "    \"\"\"\n",
    "    Resample & interpolate dataframes\n",
    "    Should NOT interpolate ePower, interpolate eMeter... \n",
    "    \"\"\"\n",
    "\n",
    "    print('----- process_dfs -----')\n",
    "    # Process NaNs\n",
    "    df_10s_processed, df_hour_processed = process_dfs(df_10s, df_hour)\n",
    "\n",
    "\n",
    "    print('----- save_df_interpolated -----')\n",
    "    save_df_processed(df_10s_processed, dwelling_id+'_10s')\n",
    "    save_df_processed(df_hour_processed, dwelling_id+'_hour')\n",
    "\n",
    "    t3 = time.time()\n",
    "    print('------------------------------ FINISHED iteration %s in %.1f [s]' % (N, (t3-t2)))\n",
    "\n",
    "t4 = time.time()\n",
    "print('Total runtime: %.1f [s]' % (t4-t1))\n",
    "\n",
    "\"\"\"\n",
    "What slows down the code a lot:\n",
    "df_nan_checker\n",
    "clean_datetime\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
