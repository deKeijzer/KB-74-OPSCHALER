{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unprocessed dwelling information extractor\n",
    "This notebook extracts usefull NaN information per dwelling and saves this into one file (csv & excel.  \n",
    "It will this for both the 10s and hour sample rate dataframes.  \n",
    "The unprocessed dataframes are loaded from: `//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//`  \n",
    "The nan information per dwelling is loaded from: `//datc//opschaler//nan_information//`  \n",
    "The final product is saved in: `//datc//opschaler//dwelling_information//total_information//`  \n",
    "It contains the following information per dwelling, for both the 10s and one hour sample rate:  \n",
    "* dwelling id  \n",
    "Dwelling id of the house.\n",
    "  \n",
    "* recorded days  \n",
    "The length of the unprocessed dataframe in days.\n",
    "\n",
    "* start date  \n",
    "The start date of the unprocessed dataframe.\n",
    "\n",
    "\n",
    "* stop date  \n",
    "The stop date of the unprocessed dataframe.\n",
    "\n",
    "* total samples (per columnm in thousands)  \n",
    "Total amount of samples in thousands, per column.\n",
    "  \n",
    "* total NaN streaks  \n",
    "Total amount of NaN streaks.\n",
    "  \n",
    "* total NaN streaks > 2  \n",
    "Total amount of NaN streaks which are larger than 2.\n",
    "  \n",
    "* total NaNs [-]  \n",
    "Total amount of NaNs in the unprocessed dataframe.\n",
    "  \n",
    "* total NaNs [%]  \n",
    "Totals NaNs devided by the total samples.\n",
    "  \n",
    "* mean of NaNs  \n",
    "Mean of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* median of NaNs  \n",
    "Median of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* std of NaNs  \n",
    "Standard deviation of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* first highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* first highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  \n",
    "* second highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* second highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  \n",
    "* third highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* third highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocessed_length_in_days(dwelling_id, type_):\n",
    "    \"\"\"\n",
    "    Get the total amount of days of the unprocessed dwelling_id.\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df = pd.read_csv(dir+dwelling_id+'_'+type_+'.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "    columns = df.columns\n",
    "    df = df['datetime'] # only keep the datetime column\n",
    "    start_date = df[0]\n",
    "    stop_date = df.iloc[-1]\n",
    "    print(type(stop_date))\n",
    "    \n",
    "    del df # Free up memory\n",
    "    recorded_days = (stop_date - start_date).days # total amount of recorded days\n",
    "    recorded_days = recorded_days.reset_index() # Messy way to convert the Series to a DataFrame\n",
    "    recorded_days = recorded_days['datetime'][0]\n",
    "\n",
    "    return recorded_days, start_date, stop_date, columns\n",
    "\n",
    "\n",
    "def nan_information_extractor(dwelling_id, path, type_):\n",
    "    \"\"\"\n",
    "    Extracts usefull information from the nan info table from a dwelling id. \n",
    "    Output is a list with this information.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.sort_values(by=['Amount of NaNs'], ascending=False) # Sort from highest to lowest amount of NaNs\n",
    "    \n",
    "    recorded_days, start_date, stop_date, columns = unprocessed_length_in_days(dwelling_id, type_) # Length of unprocessed dataframe in days\n",
    "    \n",
    "    if df.empty: # If df is empty, return nothins\n",
    "        print('Dataframe is empty: %s' % path)\n",
    "        result = list(np.full(15, np.NaN)) # Make all outputs NaN\n",
    "        result[0] = dwelling_id\n",
    "        result[1] = recorded_days\n",
    "        return result\n",
    "    else:\n",
    "\n",
    "        if type_ == 'hour':\n",
    "            length = recorded_days*24\n",
    "        elif type_ == '10s':\n",
    "            length = recorded_days*24*60*6\n",
    "        else: \n",
    "            print('type_ must be \\'hour\\' or \\'10s')\n",
    "    \n",
    "        # Calculate usefull information\n",
    "        #total_samples = length*len(columns) # get the total amount of samples in the complete df\n",
    "        total_samples = length\n",
    "        total_gaps = len(df['Amount of NaNs'])\n",
    "        total_gaps_larger_than_2 = len(df[df['Amount of NaNs'] > 2])\n",
    "        total_nans = df['Amount of NaNs'].sum()\n",
    "        total_nans_percentage = (total_nans / total_samples)*100\n",
    "        mean = df['Amount of NaNs'].mean()\n",
    "        median = df['Amount of NaNs'].median()\n",
    "        std = df['Amount of NaNs'].std()\n",
    "        \n",
    "        # Try to get relevant values for the top 3 of NaN streaks\n",
    "        # Problem with this is that often there are multiple columns which have the same NaN streak...\n",
    "        try: \n",
    "            first_highest_p = (df['Amount of NaNs'][0]/ total_samples)*100\n",
    "            first_highest_column = df['Column name'][0]\n",
    "        except:\n",
    "            print('There is no 1st highest')\n",
    "            first_highest_p = np.NaN\n",
    "            first_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            second_highest_p = (df['Amount of NaNs'][1]/ total_samples)*100\n",
    "            second_highest_column = df['Column name'][1]\n",
    "        except:\n",
    "            print('There is no 2nd highest')\n",
    "            second_highest_p = np.NaN\n",
    "            second_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            third_highest_p = (df['Amount of NaNs'][3]/ total_samples)*100\n",
    "            third_highest_column = df['Column name'][3]\n",
    "        except:\n",
    "            print('There is no 3rd highest')\n",
    "            third_highest_p = np.NaN\n",
    "            third_highest_column = np.NaN\n",
    "        \n",
    "    \n",
    "        # Put the results in a list\n",
    "        result = [dwelling_id, recorded_days, start_date, stop_date, (total_samples/1000), total_gaps, total_gaps_larger_than_2, total_nans, total_nans_percentage, mean, median, \n",
    "                  std, first_highest_p, first_highest_column, second_highest_p, second_highest_column, third_highest_p, third_highest_column]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nan_dir = '//datc//opschaler//nan_information//'\n",
    "    paths_h = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_h = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    paths_s = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_s = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    results_h = []\n",
    "    results_10s = []\n",
    "    \n",
    "    headers=['dwelling id', 'recorded days', 'start date', 'stop date', 'total samples (per column, in thousands)','total NaN streaks', 'total NaN streaks > 2','total NaNs [-]', 'total NaNs [%]', 'mean of NaNs', 'median of NaNs', 'std of NaNs', \n",
    "             'first highest NaN streak (%)', 'first highest NaN streak column', \n",
    "             'second highest NaN streak (%)', 'second highest NaN streak column', \n",
    "             'third highest NaN streak (%)', 'third highest NaN streak column']\n",
    "    \n",
    "    for i, path in enumerate(paths_h[:1]):\n",
    "        dwelling_id = ids_h[i]\n",
    "        type_ = 'hour'\n",
    "        results_h.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "    \n",
    "    for i, path in enumerate(paths_s[:1]):\n",
    "        print('10s at %s of %s' % (i, len(paths_s)))\n",
    "        dwelling_id = ids_s[i]\n",
    "        type_ = '10s'\n",
    "        results_10s.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "        \n",
    "    # make df from list of lists, round all values within to 1 decimal.\n",
    "    df_hour = pd.DataFrame.from_records(results_h, columns=headers).round(decimals=5) \n",
    "    df_10s = pd.DataFrame.from_records(results_10s, columns=headers).round(decimals=5) \n",
    "    \n",
    "    # round some numbers differently\n",
    "    one_decimal = ['total samples (per column, in thousands)', 'total NaNs [%]', 'mean of NaNs', 'std of NaNs']\n",
    "    df_hour[one_decimal] = df_hour[one_decimal].round(decimals=1) \n",
    "    df_10s[one_decimal] = df_10s[one_decimal].round(decimals=1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    # sort by recoded days, highest to lowest\n",
    "    df_hour = df_hour.sort_values(by=['recorded days'], ascending=False)\n",
    "    df_10s = df_10s.sort_values(by=['recorded days'], ascending=False)\n",
    "    \n",
    "    return df_10s, df_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run main() and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Timedelta' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-326d282a5bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time info_10s, info_hour = main() # This takes ~2,5 minutes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-5f9f99b13830>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdwelling_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hour'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresults_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnan_information_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwelling_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-7157a353c035>\u001b[0m in \u001b[0;36mnan_information_extractor\u001b[0;34m(dwelling_id, path, type_)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Amount of NaNs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Sort from highest to lowest amount of NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrecorded_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munprocessed_length_in_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwelling_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Length of unprocessed dataframe in days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# If df is empty, return nothins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-7157a353c035>\u001b[0m in \u001b[0;36munprocessed_length_in_days\u001b[0;34m(dwelling_id, type_)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;31m# Free up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrecorded_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstop_date\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;31m# total amount of recorded days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mrecorded_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecorded_days\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Messy way to convert the Series to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrecorded_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecorded_days\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Timedelta' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "%time info_10s, info_hour = main() # This takes ~2,5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwelling id</th>\n",
       "      <th>recorded days</th>\n",
       "      <th>start date</th>\n",
       "      <th>stop date</th>\n",
       "      <th>total samples (per column, in thousands)</th>\n",
       "      <th>total NaN streaks</th>\n",
       "      <th>total NaN streaks &gt; 2</th>\n",
       "      <th>total NaNs [-]</th>\n",
       "      <th>total NaNs [%]</th>\n",
       "      <th>mean of NaNs</th>\n",
       "      <th>median of NaNs</th>\n",
       "      <th>std of NaNs</th>\n",
       "      <th>first highest NaN streak (%)</th>\n",
       "      <th>first highest NaN streak column</th>\n",
       "      <th>second highest NaN streak (%)</th>\n",
       "      <th>second highest NaN streak column</th>\n",
       "      <th>third highest NaN streak (%)</th>\n",
       "      <th>third highest NaN streak column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01S01W7548</td>\n",
       "      <td>83</td>\n",
       "      <td>2017-03-07 15:00:00</td>\n",
       "      <td>2014   2017-05-30 13:00:00\n",
       "Name: datetime, dty...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>528</td>\n",
       "      <td>26.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>eMeter</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>eMeter</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>eMeterReturn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dwelling id  recorded days          start date  \\\n",
       "0  P01S01W7548             83 2017-03-07 15:00:00   \n",
       "\n",
       "                                           stop date  \\\n",
       "0  2014   2017-05-30 13:00:00\n",
       "Name: datetime, dty...   \n",
       "\n",
       "   total samples (per column, in thousands)  total NaN streaks  \\\n",
       "0                                       2.0                 32   \n",
       "\n",
       "   total NaN streaks > 2  total NaNs [-]  total NaNs [%]  mean of NaNs  \\\n",
       "0                      9             528            26.5          16.5   \n",
       "\n",
       "   median of NaNs  std of NaNs  first highest NaN streak (%)  \\\n",
       "0             1.0         26.8                        0.0502   \n",
       "\n",
       "  first highest NaN streak column  second highest NaN streak (%)  \\\n",
       "0                          eMeter                         0.0502   \n",
       "\n",
       "  second highest NaN streak column  third highest NaN streak (%)  \\\n",
       "0                           eMeter                        0.0502   \n",
       "\n",
       "  third highest NaN streak column  \n",
       "0                    eMeterReturn  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "info_hour.to_csv('//datc//opschaler//dwelling_information//total_information//total_nan_information_hour.csv', sep='\\t', index=False)\n",
    "info_10s.to_csv('//datc//opschaler//dwelling_information//total_information//nan_information_10s.csv', sep='\\t', index=False)\n",
    "\n",
    "# Also save to Excel\n",
    "writer = pd.ExcelWriter('//datc//opschaler//dwelling_information//total_information//total_nan_information.xlsx')\n",
    "info_hour.to_excel(writer,'Hour dataframes', index=False)\n",
    "info_10s.to_excel(writer,'10s dataframes', index=False)\n",
    "writer.save()\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
