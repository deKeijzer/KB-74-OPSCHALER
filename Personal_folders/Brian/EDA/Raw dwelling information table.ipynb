{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unprocessed dwelling information extractor\n",
    "This notebook extracts usefull NaN information per dwelling and saves this into one file (csv & excel.  \n",
    "It will this for both the 10s and hour sample rate dataframes.  \n",
    "The unprocessed dataframes are loaded from: `//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//`  \n",
    "The nan information per dwelling is loaded from: `//datc//opschaler//nan_information//`  \n",
    "The final product is saved in: `//datc//opschaler//dwelling_information//total_information//`  \n",
    "It contains the following information per dwelling, for both the 10s and one hour sample rate:  \n",
    "* dwelling id  \n",
    "Dwelling id of the house.\n",
    "  \n",
    "* recorded days  \n",
    "The length of the unprocessed dataframe in days.\n",
    "  \n",
    "* total samples (per columnm in thousands)  \n",
    "Total amount of samples in thousands, per column.\n",
    "  \n",
    "* total NaN streaks  \n",
    "Total amount of NaN streaks.\n",
    "  \n",
    "* total NaN streaks > 2  \n",
    "Total amount of NaN streaks which are larger than 2.\n",
    "  \n",
    "* total NaNs [-]  \n",
    "Total amount of NaNs in the unprocessed dataframe.\n",
    "  \n",
    "* total NaNs [%]  \n",
    "Totals NaNs devided by the total samples.\n",
    "  \n",
    "* mean of NaNs  \n",
    "Mean of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* median of NaNs  \n",
    "Median of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* std of NaNs  \n",
    "Standard deviation of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* first highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* first highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  \n",
    "* second highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* second highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  \n",
    "* third highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* third highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocessed_length_in_days(dwelling_id, type_):\n",
    "    \"\"\"\n",
    "    Get the total amount of days of the unprocessed dwelling_id.\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df = pd.read_csv(dir+dwelling_id+'_'+type_+'.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "    columns = df.columns\n",
    "    df = df['datetime'] # only keep the datetime column\n",
    "    start_date = df[0]\n",
    "    stop_date = df[-1:]\n",
    "    \n",
    "    del df # Free up memory\n",
    "    recorded_days = (stop_date - start_date).dt.days # total amount of recorded days\n",
    "    recorded_days = recorded_days.reset_index() # Messy way to convert the Series to a DataFrame\n",
    "    recorded_days = recorded_days['datetime'][0]\n",
    "\n",
    "    return recorded_days, columns\n",
    "\n",
    "\n",
    "def nan_information_extractor(dwelling_id, path, type_):\n",
    "    \"\"\"\n",
    "    Extracts usefull information from the nan info table from a dwelling id. \n",
    "    Output is a list with this information.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.sort_values(by=['Amount of NaNs'], ascending=False) # Sort from highest to lowest amount of NaNs\n",
    "    \n",
    "    recorded_days, columns = unprocessed_length_in_days(dwelling_id, type_) # Length of unprocessed dataframe in days\n",
    "    \n",
    "    if df.empty: # If df is empty, return nothins\n",
    "        print('Dataframe is empty: %s' % path)\n",
    "        result = list(np.full(15, np.NaN)) # Make all outputs NaN\n",
    "        result[0] = dwelling_id\n",
    "        result[1] = recorded_days\n",
    "        return result\n",
    "    else:\n",
    "\n",
    "        if type_ == 'hour':\n",
    "            length = recorded_days*24\n",
    "        elif type_ == '10s':\n",
    "            length = recorded_days*24*60*6\n",
    "        else: \n",
    "            print('type_ must be \\'hour\\' or \\'10s')\n",
    "    \n",
    "        # Calculate usefull information\n",
    "        #total_samples = length*len(columns) # get the total amount of samples in the complete df\n",
    "        total_samples = length\n",
    "        total_gaps = len(df['Amount of NaNs'])\n",
    "        total_gaps_larger_than_2 = len(df[df['Amount of NaNs'] > 2])\n",
    "        total_nans = df['Amount of NaNs'].sum()\n",
    "        total_nans_percentage = (total_nans / total_samples)*100\n",
    "        mean = df['Amount of NaNs'].mean()\n",
    "        median = df['Amount of NaNs'].median()\n",
    "        std = df['Amount of NaNs'].std()\n",
    "        \n",
    "        # Try to get relevant values for the top 3 of NaN streaks\n",
    "        # Problem with this is that often there are multiple columns which have the same NaN streak...\n",
    "        try: \n",
    "            first_highest_p = (df['Amount of NaNs'][0]/ total_samples)*100\n",
    "            first_highest_column = df['Column name'][0]\n",
    "        except:\n",
    "            print('There is no 1st highest')\n",
    "            first_highest_p = np.NaN\n",
    "            first_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            second_highest_p = (df['Amount of NaNs'][1]/ total_samples)*100\n",
    "            second_highest_column = df['Column name'][1]\n",
    "        except:\n",
    "            print('There is no 2nd highest')\n",
    "            second_highest_p = np.NaN\n",
    "            second_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            third_highest_p = (df['Amount of NaNs'][3]/ total_samples)*100\n",
    "            third_highest_column = df['Column name'][3]\n",
    "        except:\n",
    "            print('There is no 3rd highest')\n",
    "            third_highest_p = np.NaN\n",
    "            third_highest_column = np.NaN\n",
    "        \n",
    "    \n",
    "        # Put the results in a list\n",
    "        result = [dwelling_id, recorded_days, total_samples, total_gaps, total_gaps_larger_than_2, total_nans, total_nans_percentage, mean, median, \n",
    "                  std, first_highest_p, first_highest_column, second_highest_p, second_highest_column, third_highest_p, third_highest_column]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nan_dir = '//datc//opschaler//nan_information//'\n",
    "    paths_h = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_h = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    paths_s = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_s = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    results_h = []\n",
    "    results_10s = []\n",
    "    \n",
    "    headers=['dwelling id', 'recorded days', 'total samples (per column, in thousands)','total NaN streaks', 'total NaN streaks > 2','total NaNs [-]', 'total NaNs [%]', 'mean of NaNs', 'median of NaNs', 'std of NaNs', \n",
    "             'first highest NaN streak (%)', 'first highest NaN streak column', \n",
    "             'second highest NaN streak (%)', 'second highest NaN streak column', \n",
    "             'third highest NaN streak (%)', 'third highest NaN streak column']\n",
    "    \n",
    "    for i, path in enumerate(paths_h):\n",
    "        dwelling_id = ids_h[i]\n",
    "        type_ = 'hour'\n",
    "        results_h.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "    \n",
    "    for i, path in enumerate(paths_s):\n",
    "        print('10s at %s of %s' % (i, len(paths_s)))\n",
    "        dwelling_id = ids_s[i]\n",
    "        type_ = '10s'\n",
    "        results_10s.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "        \n",
    "    # make df from list of lists, round all values within to 1 decimal.\n",
    "    df_hour = pd.DataFrame.from_records(results_h, columns=headers)\n",
    "    # round some numbers\n",
    "    \n",
    "    df_10s = pd.DataFrame.from_records(results_10s, columns=headers)\n",
    "    \n",
    "    # sort by recoded days, highest to lowest\n",
    "    df_hour = df_hour.sort_values(by=['recorded days'], ascending=False) \n",
    "    df_10s = df_10s.sort_values(by=['recorded days'], ascending=False) \n",
    "    \n",
    "    return df_10s, df_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run main() and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 24\n",
      "145 24\n",
      "132 24\n",
      "84 24\n",
      "83 24\n",
      "1 24\n",
      "85 24\n",
      "85 24\n",
      "74 24\n",
      "83 24\n",
      "39 24\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W7042_hour.csv\n",
      "86 24\n",
      "83 24\n",
      "147 24\n",
      "84 24\n",
      "27 24\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W1554_hour.csv\n",
      "76 24\n",
      "87 24\n",
      "220 24\n",
      "211 24\n",
      "85 24\n",
      "83 24\n",
      "83 24\n",
      "128 24\n",
      "96 24\n",
      "210 24\n",
      "23 24\n",
      "26 24\n",
      "There is no 3rd highest\n",
      "82 24\n",
      "98 24\n",
      "155 24\n",
      "92 24\n",
      "22 24\n",
      "141 24\n",
      "76 24\n",
      "83 24\n",
      "83 24\n",
      "84 24\n",
      "84 24\n",
      "83 24\n",
      "83 24\n",
      "83 24\n",
      "146 24\n",
      "94 24\n",
      "26 24\n",
      "86 24\n",
      "85 24\n",
      "212 24\n",
      "147 24\n",
      "86 24\n",
      "84 24\n",
      "0 24\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W0001_hour.csv\n",
      "83 24\n",
      "85 24\n",
      "85 24\n",
      "152 24\n",
      "10s at 0 of 56\n",
      "83 24\n",
      "10s at 1 of 56\n",
      "145 24\n",
      "10s at 2 of 56\n",
      "132 24\n",
      "10s at 3 of 56\n",
      "84 24\n",
      "10s at 4 of 56\n",
      "83 24\n",
      "10s at 5 of 56\n",
      "1 24\n",
      "10s at 6 of 56\n",
      "85 24\n",
      "10s at 7 of 56\n",
      "85 24\n",
      "10s at 8 of 56\n",
      "74 24\n",
      "10s at 9 of 56\n",
      "83 24\n",
      "10s at 10 of 56\n",
      "39 24\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W7042_hour.csv\n",
      "10s at 11 of 56\n",
      "86 24\n",
      "10s at 12 of 56\n",
      "83 24\n",
      "10s at 13 of 56\n",
      "147 24\n",
      "10s at 14 of 56\n",
      "84 24\n",
      "10s at 15 of 56\n",
      "27 24\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W1554_hour.csv\n",
      "10s at 16 of 56\n",
      "76 24\n",
      "10s at 17 of 56\n",
      "87 24\n",
      "10s at 18 of 56\n",
      "220 24\n",
      "10s at 19 of 56\n",
      "211 24\n",
      "10s at 20 of 56\n",
      "85 24\n",
      "10s at 21 of 56\n",
      "83 24\n",
      "10s at 22 of 56\n",
      "83 24\n",
      "10s at 23 of 56\n",
      "128 24\n",
      "10s at 24 of 56\n"
     ]
    }
   ],
   "source": [
    "%time info_10s, info_hour = main() # This takes ~2,5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info_hour.to_csv('//datc//opschaler//dwelling_information//total_information//total_nan_information_hour.csv', sep='\\t', index=False)\n",
    "info_10s.to_csv('//datc//opschaler//dwelling_information//total_information//nan_information_10s.csv', sep='\\t', index=False)\n",
    "\n",
    "# Also save to Excel\n",
    "writer = pd.ExcelWriter('//datc//opschaler//dwelling_information//total_information//total_nan_information.xlsx')\n",
    "info_hour.to_excel(writer,'Hour dataframes', index=False)\n",
    "info_10s.to_excel(writer,'10s dataframes', index=False)\n",
    "writer.save()\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
