{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unprocessed dwelling information extractor\n",
    "This notebook extracts usefull NaN information per dwelling and saves this into one file (csv & excel.  \n",
    "It will this for both the 10s and hour sample rate dataframes.  \n",
    "The unprocessed dataframes are loaded from: `//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//`  \n",
    "The nan information per dwelling is loaded from: `//datc//opschaler//nan_information//`  \n",
    "The final product is saved in: `//datc//opschaler//dwelling_information//total_information//`  \n",
    "It contains the following information per dwelling, for both the 10s and one hour sample rate:  \n",
    "* dwelling id\n",
    "* recorded days\n",
    "* total NaN streaks \n",
    "* total NaN streaks > 2\n",
    "* total NaNs [-]\n",
    "* total NaNs [%]\n",
    "* mean of NaNs\n",
    "* median of NaNs\n",
    "* std of NaNs\n",
    "* first highest NaN streak (%)\n",
    "* first highest NaN streak column\n",
    "* second highest NaN streak (%)\n",
    "* second highest NaN streak column\n",
    "* third highest NaN streak (%)\n",
    "* third highest NaN streak column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocessed_length_in_days(dwelling_id, type_):\n",
    "    \"\"\"\n",
    "    Get the total amount of days of the unprocessed dwelling_id.\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df = pd.read_csv(dir+dwelling_id+'_'+type_+'.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "    columns = df.columns\n",
    "    df = df['datetime'] # only keep the datetime column\n",
    "    start_date = df[0]\n",
    "    stop_date = df[-1:]\n",
    "    \n",
    "    del df # Free up memory\n",
    "    total_days = (stop_date - start_date).dt.days # total amount of recorded days\n",
    "    total_days = total_days.reset_index() # Messy way to convert the Series to a DataFrame\n",
    "\n",
    "    return total_days['datetime'][0], columns\n",
    "\n",
    "\n",
    "def nan_information_extractor(dwelling_id, path, type_):\n",
    "    \"\"\"\n",
    "    Extracts usefull information from the nan info table from a dwelling id. \n",
    "    Output is a list with this information.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.sort_values(by=['Amount of NaNs'], ascending=False) # Sort from highest to lowest amount of NaNs\n",
    "    \n",
    "    recorded_days, columns = unprocessed_length_in_days(dwelling_id, type_) # Length of unprocessed dataframe in days\n",
    "    \n",
    "    if df.empty: # If df is empty, return nothins\n",
    "        print('Dataframe is empty: %s' % path)\n",
    "        result = list(np.full(14, np.NaN)) # Make all outputs NaN\n",
    "        result[0] = dwelling_id\n",
    "        result[1] = recorded_days\n",
    "        return result\n",
    "    else:\n",
    "\n",
    "        if type_ == 'hour':\n",
    "            length = recorded_days*24\n",
    "        elif type_ == '10s':\n",
    "            length = recorded_days*24*60*6\n",
    "        else: \n",
    "            print('type_ must be \\'hour\\' or \\'10s')\n",
    "    \n",
    "        # Calculate usefull information\n",
    "        total_gaps = len(df['Amount of NaNs'])\n",
    "        total_gaps_larger_than_2 = len(df[df['Amount of NaNs'] > 2])\n",
    "        total_nans = df['Amount of NaNs'].sum()\n",
    "        total_nans_percentage = (total_nans / (length*len(columns)))*100\n",
    "        mean = df['Amount of NaNs'].mean()\n",
    "        median = df['Amount of NaNs'].median()\n",
    "        std = df['Amount of NaNs'].std()\n",
    "        \n",
    "        # Try to get relevant values for the top 3 of NaN streaks\n",
    "        # Problem with this is that often there are multiple columns which have the same NaN streak...\n",
    "        try: \n",
    "            first_highest_p = (df['Amount of NaNs'][0]/ length)*100\n",
    "            first_highest_column = df['Column name'][0]\n",
    "        except:\n",
    "            print('There is no 1st highest')\n",
    "            first_highest_p = np.NaN\n",
    "            first_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            second_highest_p = (df['Amount of NaNs'][1]/ length)*100\n",
    "            second_highest_column = df['Column name'][1]\n",
    "        except:\n",
    "            print('There is no 2nd highest')\n",
    "            second_highest_p = np.NaN\n",
    "            second_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            third_highest_p = (df['Amount of NaNs'][3]/ length)*100\n",
    "            third_highest_column = df['Column name'][3]\n",
    "        except:\n",
    "            print('There is no 3rd highest')\n",
    "            third_highest_p = np.NaN\n",
    "            third_highest_column = np.NaN\n",
    "        \n",
    "    \n",
    "        # Put the results in a list\n",
    "        result = [dwelling_id, recorded_days, total_gaps, total_gaps_larger_than_2, total_nans, total_nans_percentage, mean, median, \n",
    "                  std, first_highest_p, first_highest_column, second_highest_p, second_highest_column, third_highest_p, third_highest_column]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nan_dir = '//datc//opschaler//nan_information//'\n",
    "    paths_h = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_h = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    paths_s = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_s = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    results_h = []\n",
    "    results_10s = []\n",
    "    \n",
    "    headers=['dwelling id', 'recorded days', 'total NaN streaks', 'total NaN streaks > 2','total NaNs [-]', 'total NaNs [%]', 'mean of NaNs', 'median of NaNs', 'std of NaNs', \n",
    "             'first highest NaN streak (%)', 'first highest NaN streak column', \n",
    "             'second highest NaN streak (%)', 'second highest NaN streak column', \n",
    "             'third highest NaN streak (%)', 'third highest NaN streak column']\n",
    "    \n",
    "    for i, path in enumerate(paths_h):\n",
    "        dwelling_id = ids_h[i]\n",
    "        type_ = 'hour'\n",
    "        results_h.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "    \n",
    "    for i, path in enumerate(paths_s):\n",
    "        print('10s at %s of %s' % (i, len(paths_s)))\n",
    "        dwelling_id = ids_s[i]\n",
    "        type_ = '10s'\n",
    "        results_10s.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "        \n",
    "    # make df from list of lists, round all values within to 1 decimal.\n",
    "    df_hour = pd.DataFrame.from_records(results_h, columns=headers).round(decimals=3) \n",
    "    df_10s = pd.DataFrame.from_records(results_10s, columns=headers).round(decimals=3) \n",
    "    \n",
    "    # sort by recoded days, highest to lowest\n",
    "    df_hour = df_hour.sort_values(by=['recorded days'], ascending=False) \n",
    "    df_10s = df_10s.sort_values(by=['recorded days'], ascending=False) \n",
    "    \n",
    "    return df_10s, df_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run main() and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W7042_hour.csv\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W1554_hour.csv\n",
      "There is no 3rd highest\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W0001_hour.csv\n",
      "10s at 0 of 56\n",
      "10s at 1 of 56\n",
      "10s at 2 of 56\n",
      "10s at 3 of 56\n",
      "10s at 4 of 56\n",
      "10s at 5 of 56\n",
      "10s at 6 of 56\n",
      "10s at 7 of 56\n",
      "10s at 8 of 56\n",
      "10s at 9 of 56\n",
      "10s at 10 of 56\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W7042_hour.csv\n",
      "10s at 11 of 56\n",
      "10s at 12 of 56\n",
      "10s at 13 of 56\n",
      "10s at 14 of 56\n",
      "10s at 15 of 56\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W1554_hour.csv\n",
      "10s at 16 of 56\n",
      "10s at 17 of 56\n",
      "10s at 18 of 56\n",
      "10s at 19 of 56\n",
      "10s at 20 of 56\n",
      "10s at 21 of 56\n",
      "10s at 22 of 56\n",
      "10s at 23 of 56\n",
      "10s at 24 of 56\n",
      "10s at 25 of 56\n",
      "10s at 26 of 56\n",
      "10s at 27 of 56\n",
      "There is no 3rd highest\n",
      "10s at 28 of 56\n",
      "10s at 29 of 56\n",
      "10s at 30 of 56\n",
      "10s at 31 of 56\n",
      "10s at 32 of 56\n",
      "10s at 33 of 56\n",
      "10s at 34 of 56\n",
      "10s at 35 of 56\n",
      "10s at 36 of 56\n",
      "10s at 37 of 56\n",
      "10s at 38 of 56\n",
      "10s at 39 of 56\n",
      "10s at 40 of 56\n",
      "10s at 41 of 56\n",
      "10s at 42 of 56\n",
      "10s at 43 of 56\n",
      "10s at 44 of 56\n",
      "10s at 45 of 56\n",
      "10s at 46 of 56\n",
      "10s at 47 of 56\n",
      "10s at 48 of 56\n",
      "10s at 49 of 56\n",
      "10s at 50 of 56\n",
      "10s at 51 of 56\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W0001_hour.csv\n",
      "10s at 52 of 56\n",
      "10s at 53 of 56\n",
      "10s at 54 of 56\n",
      "10s at 55 of 56\n",
      "CPU times: user 2min 8s, sys: 12.6 s, total: 2min 21s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%time info_hour, info_10s = main() # This takes ~2,5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "info_hour.to_csv('//datc//opschaler//dwelling_information//total_information//total_nan_information_hour.csv', sep='\\t', index=False)\n",
    "info_10s.to_csv('//datc//opschaler//dwelling_information//total_information//nan_information_10s.csv', sep='\\t', index=False)\n",
    "\n",
    "# Also save to Excel\n",
    "writer = pd.ExcelWriter('//datc//opschaler//dwelling_information//total_information//total_nan_information.xlsx')\n",
    "info_hour.to_excel(writer,'Hour dataframes', index=False)\n",
    "info_10s.to_excel(writer,'10s dataframes', index=False)\n",
    "writer.save()\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
