{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocessed_length_in_days(dwelling_id, type_):\n",
    "    \"\"\"\n",
    "    Get the total amount of days of the unprocessed dwelling_id.\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df = pd.read_csv(dir+dwelling_id+'_'+type_+'.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "    columns = df.columns\n",
    "    df = df['datetime'] # only keep the datetime column\n",
    "    start_date = df[0]\n",
    "    stop_date = df[-1:]\n",
    "    \n",
    "    del df # Free up memory\n",
    "    total_days = (stop_date - start_date).dt.days # total amount of recorded days\n",
    "    total_days = total_days.reset_index() # Messy way to convert the Series to a DataFrame\n",
    "\n",
    "    return total_days['datetime'][0], columns\n",
    "\n",
    "\n",
    "def nan_information_extractor(dwelling_id, path, type_):\n",
    "    \"\"\"\n",
    "    Extracts usefull information from the nan info table from a dwelling id. \n",
    "    Output is a list with this information.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.sort_values(by=['Amount of NaNs'], ascending=False) # Sort from highest to lowest amount of NaNs\n",
    "    \n",
    "    recorded_days, columns = unprocessed_length_in_days(dwelling_id, type_) # Length of unprocessed dataframe in days\n",
    "    \n",
    "    if df.empty: # If df is empty, return nothins\n",
    "        print('Dataframe is empty: %s' % path)\n",
    "        result = list(np.full(14, np.NaN)) # Make all outputs NaN\n",
    "        result[0] = dwelling_id\n",
    "        result[1] = recorded_days\n",
    "        return result\n",
    "    else:\n",
    "\n",
    "        if type_ == 'hour':\n",
    "            length = recorded_days*24\n",
    "        elif type_ == '10s':\n",
    "            length = recorded_days*24*60*6\n",
    "        else: \n",
    "            print('type_ must be \\'hour\\' or \\'10s')\n",
    "    \n",
    "        # Calculate usefull information\n",
    "        total_gaps = len(df['Amount of NaNs'])\n",
    "        total_gaps_larger_than_2 = len(df[df['Amount of NaNs'] > 2])\n",
    "        total_nans = df['Amount of NaNs'].sum()\n",
    "        total_nans_percentage = (total_nans / (length*len(columns)))*100\n",
    "        mean = df['Amount of NaNs'].mean()\n",
    "        median = df['Amount of NaNs'].median()\n",
    "        std = df['Amount of NaNs'].std()\n",
    "        \n",
    "        # Try to get relevant values for the top 3 of NaN streaks\n",
    "        # Problem with this is that often there are multiple columns which have the same NaN streak...\n",
    "        try: \n",
    "            first_highest_p = (df['Amount of NaNs'][0]/ length)*100\n",
    "            first_highest_column = df['Column name'][0]\n",
    "        except:\n",
    "            print('There is no 1st highest')\n",
    "            first_highest_p = np.NaN\n",
    "            first_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            second_highest_p = (df['Amount of NaNs'][1]/ length)*100\n",
    "            second_highest_column = df['Column name'][1]\n",
    "        except:\n",
    "            print('There is no 2nd highest')\n",
    "            second_highest_p = np.NaN\n",
    "            second_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            third_highest_p = (df['Amount of NaNs'][3]/ length)*100\n",
    "            third_highest_column = df['Column name'][3]\n",
    "        except:\n",
    "            print('There is no 3rd highest')\n",
    "            third_highest_p = np.NaN\n",
    "            third_highest_column = np.NaN\n",
    "        \n",
    "    \n",
    "        # Put the results in a list\n",
    "        result = [dwelling_id, recorded_days, total_gaps, total_gaps_larger_than_2, total_nans, total_nans_percentage, mean, median, \n",
    "                  std, first_highest_p, first_highest_column, second_highest_p, second_highest_column, third_highest_p, third_highest_column]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nan_dir = '//datc//opschaler//nan_information//'\n",
    "    paths_h = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_h = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    paths_s = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_s = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    results_h = []\n",
    "    results_10s = []\n",
    "    \n",
    "    headers=['dwelling id', 'recorded days', 'total NaN streaks', 'total NaN streaks > 2','total NaNs [-]', 'total NaNs [%]', 'mean of NaNs', 'median of NaNs', 'std of NaNs', \n",
    "             'first highest NaN streak (%)', 'first highest NaN streak column', \n",
    "             'second highest NaN streak (%)', 'second highest NaN streak column', \n",
    "             'third highest NaN streak (%)', 'third highest NaN streak column']\n",
    "    \n",
    "    for i, path in enumerate(paths_h):\n",
    "        dwelling_id = ids_h[i]\n",
    "        type_ = 'hour'\n",
    "        results_h.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "    \n",
    "    for i, path in enumerate(paths_s):\n",
    "        print('10s at %s of %s' % (i, len(paths_s)))\n",
    "        dwelling_id = ids_s[i]\n",
    "        type_ = '10s'\n",
    "        results_10s.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "        \n",
    "    # make df from list of lists, round all values within to 1 decimal.\n",
    "    df_hour = pd.DataFrame.from_records(results_h, columns=headers).round(decimals=1) \n",
    "    df_10s = pd.DataFrame.from_records(results_10s, columns=headers).round(decimals=1) \n",
    "    \n",
    "    # sort by recoded days, highest to lowest\n",
    "    df_hour = df_hour.sort_values(by=['recorded days'], ascending=False) \n",
    "    df_10s = df_10s.sort_values(by=['recorded days'], ascending=False) \n",
    "    \n",
    "    return df_10s, df_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W7042_hour.csv\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W1554_hour.csv\n",
      "There is no 3rd highest\n",
      "Dataframe is empty: //datc//opschaler//nan_information/P01S01W0001_hour.csv\n",
      "10s at 0 of 56\n",
      "10s at 1 of 56\n",
      "10s at 2 of 56\n",
      "10s at 3 of 56\n",
      "10s at 4 of 56\n",
      "10s at 5 of 56\n",
      "10s at 6 of 56\n",
      "10s at 7 of 56\n",
      "10s at 8 of 56\n",
      "10s at 9 of 56\n"
     ]
    }
   ],
   "source": [
    "%time info_hour, info_10s = main() # This takes ~2,5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_hour.to_csv('//datc//opschaler//dwelling_information//total_information//total_nan_information_hour.csv', sep='\\t', index=False)\n",
    "info_10s.to_csv('//datc//opschaler//dwelling_information//total_information//nan_information_10s.csv', sep='\\t', index=False)\n",
    "\n",
    "# Also save to Excel\n",
    "writer = pd.ExcelWriter('//datc//opschaler//dwelling_information//total_information//total_nan_information.xlsx')\n",
    "info_hour.to_excel(writer,'Hour dataframes', index=False)\n",
    "info_10s.to_excel(writer,'10s dataframes', index=False)\n",
    "writer.save()\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
