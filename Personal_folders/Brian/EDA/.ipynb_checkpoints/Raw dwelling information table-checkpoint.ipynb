{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unprocessed dwelling information extractor\n",
    "This notebook extracts usefull NaN information per dwelling and saves this into one file (csv & excel.  \n",
    "It will this for both the 10s and hour sample rate dataframes.  \n",
    "The unprocessed dataframes are loaded from: `//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//`  \n",
    "The nan information per dwelling is loaded from: `//datc//opschaler//nan_information//`  \n",
    "The final product is saved in: `//datc//opschaler//dwelling_information//total_information//`  \n",
    "It contains the following information per dwelling, for both the 10s and one hour sample rate:  \n",
    "* dwelling id  \n",
    "Dwelling id of the house.\n",
    "  \n",
    "* recorded days  \n",
    "The length of the unprocessed dataframe in days.\n",
    "\n",
    "* start date  \n",
    "The start date of the unprocessed dataframe.\n",
    "\n",
    "\n",
    "* stop date  \n",
    "The stop date of the unprocessed dataframe.\n",
    "\n",
    "* total samples (per columnm in thousands)  \n",
    "Total amount of samples in thousands, per column.\n",
    "  \n",
    "* total NaN streaks  \n",
    "Total amount of NaN streaks.\n",
    "  \n",
    "* total NaN streaks > 2  \n",
    "Total amount of NaN streaks which are larger than 2.\n",
    "  \n",
    "* total NaNs [-]  \n",
    "Total amount of NaNs in the unprocessed dataframe.\n",
    "  \n",
    "* total NaNs [%]  \n",
    "Totals NaNs devided by the total samples.\n",
    "  \n",
    "* mean of NaNs  \n",
    "Mean of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* median of NaNs  \n",
    "Median of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* std of NaNs  \n",
    "Standard deviation of the amount of NaNs per NaN streak.\n",
    "  \n",
    "* first highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* first highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  \n",
    "* second highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* second highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  \n",
    "* third highest NaN streak (%)  \n",
    "Amount of NaNs from the first highest NaN streak, devided by the total samples.\n",
    "  \n",
    "* third highest NaN streak column  \n",
    "The name of the column where the first highest NaN streak is in.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocessed_length_in_days(dwelling_id, type_):\n",
    "    \"\"\"\n",
    "    Get the total amount of days of the unprocessed dwelling_id.\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df = pd.read_csv(dir+dwelling_id+'_'+type_+'.csv', delimiter='\\t', parse_dates=['datetime'])\n",
    "    columns = df.columns\n",
    "    df = df['datetime'] # only keep the datetime column\n",
    "    start_date = df.iloc[0]\n",
    "    stop_date = df.iloc[-1]\n",
    "    print(type(stop_date))\n",
    "    \n",
    "    del df # Free up memory\n",
    "    \n",
    "    recorded_days = (stop_date - start_date).days # total amount of recorded days\n",
    "\n",
    "    return recorded_days, start_date, stop_date, columns\n",
    "\n",
    "\n",
    "def nan_information_extractor(dwelling_id, path, type_):\n",
    "    \"\"\"\n",
    "    Extracts usefull information from the nan info table from a dwelling id. \n",
    "    Output is a list with this information.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "    df = df.sort_values(by=['Amount of NaNs'], ascending=False) # Sort from highest to lowest amount of NaNs\n",
    "    \n",
    "    recorded_days, start_date, stop_date, columns = unprocessed_length_in_days(dwelling_id, type_) # Length of unprocessed dataframe in days\n",
    "    \n",
    "    if df.empty: # If df is empty, return nothins\n",
    "        print('Dataframe is empty: %s' % path)\n",
    "        result = list(np.full(15, np.NaN)) # Make all outputs NaN\n",
    "        result[0] = dwelling_id\n",
    "        result[1] = recorded_days\n",
    "        return result\n",
    "    else:\n",
    "\n",
    "        if type_ == 'hour':\n",
    "            length = recorded_days*24\n",
    "        elif type_ == '10s':\n",
    "            length = recorded_days*24*60*6\n",
    "        else: \n",
    "            print('type_ must be \\'hour\\' or \\'10s')\n",
    "    \n",
    "        # Calculate usefull information\n",
    "        #total_samples = length*len(columns) # get the total amount of samples in the complete df\n",
    "        total_samples = length\n",
    "        total_gaps = len(df['Amount of NaNs'])\n",
    "        total_gaps_larger_than_2 = len(df[df['Amount of NaNs'] > 2])\n",
    "        total_nans = df['Amount of NaNs'].sum()\n",
    "        total_nans_percentage = (total_nans / total_samples)*100\n",
    "        mean = df['Amount of NaNs'].mean()\n",
    "        median = df['Amount of NaNs'].median()\n",
    "        std = df['Amount of NaNs'].std()\n",
    "        \n",
    "        # Try to get relevant values for the top 3 of NaN streaks\n",
    "        # Problem with this is that often there are multiple columns which have the same NaN streak...\n",
    "        try: \n",
    "            first_highest_p = (df['Amount of NaNs'][0]/ total_samples)*100\n",
    "            first_highest_column = df['Column name'][0]\n",
    "        except:\n",
    "            print('There is no 1st highest')\n",
    "            first_highest_p = np.NaN\n",
    "            first_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            second_highest_p = (df['Amount of NaNs'][1]/ total_samples)*100\n",
    "            second_highest_column = df['Column name'][1]\n",
    "        except:\n",
    "            print('There is no 2nd highest')\n",
    "            second_highest_p = np.NaN\n",
    "            second_highest_column = np.NaN\n",
    "        \n",
    "        try:\n",
    "            third_highest_p = (df['Amount of NaNs'][3]/ total_samples)*100\n",
    "            third_highest_column = df['Column name'][3]\n",
    "        except:\n",
    "            print('There is no 3rd highest')\n",
    "            third_highest_p = np.NaN\n",
    "            third_highest_column = np.NaN\n",
    "        \n",
    "    \n",
    "        # Put the results in a list\n",
    "        result = [dwelling_id, recorded_days, start_date, stop_date, (total_samples/1000), total_gaps, total_gaps_larger_than_2, total_nans, total_nans_percentage, mean, median, \n",
    "                  std, first_highest_p, first_highest_column, second_highest_p, second_highest_column, third_highest_p, third_highest_column]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nan_dir = '//datc//opschaler//nan_information//'\n",
    "    paths_h = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_h = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    paths_s = glob.glob(nan_dir+'*_hour.csv')\n",
    "    ids_s = list(map(lambda x: x[-20:-9], paths_h))\n",
    "    \n",
    "    results_h = []\n",
    "    results_10s = []\n",
    "    \n",
    "    headers=['dwelling id', 'recorded days', 'start date', 'stop date', 'total samples (per column, in thousands)','total NaN streaks', 'total NaN streaks > 2','total NaNs [-]', 'total NaNs [%]', 'mean of NaNs', 'median of NaNs', 'std of NaNs', \n",
    "             'first highest NaN streak (%)', 'first highest NaN streak column', \n",
    "             'second highest NaN streak (%)', 'second highest NaN streak column', \n",
    "             'third highest NaN streak (%)', 'third highest NaN streak column']\n",
    "    \n",
    "    for i, path in enumerate(paths_h[:1]):\n",
    "        dwelling_id = ids_h[i]\n",
    "        type_ = 'hour'\n",
    "        results_h.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "    \n",
    "    for i, path in enumerate(paths_s[:1]):\n",
    "        print('10s at %s of %s' % (i, len(paths_s)))\n",
    "        dwelling_id = ids_s[i]\n",
    "        type_ = '10s'\n",
    "        results_10s.append(nan_information_extractor(dwelling_id, path, type_))\n",
    "        \n",
    "    # make df from list of lists, round all values within to 1 decimal.\n",
    "    df_hour = pd.DataFrame.from_records(results_h, columns=headers).round(decimals=5) \n",
    "    df_10s = pd.DataFrame.from_records(results_10s, columns=headers).round(decimals=5) \n",
    "    \n",
    "    # round some numbers differently\n",
    "    one_decimal = ['total samples (per column, in thousands)', 'total NaNs [%]', 'mean of NaNs', 'std of NaNs']\n",
    "    df_hour[one_decimal] = df_hour[one_decimal].round(decimals=1) \n",
    "    df_10s[one_decimal] = df_10s[one_decimal].round(decimals=1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    # sort by recoded days, highest to lowest\n",
    "    df_hour = df_hour.sort_values(by=['recorded days'], ascending=False)\n",
    "    df_10s = df_10s.sort_values(by=['recorded days'], ascending=False)\n",
    "    \n",
    "    return df_10s, df_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run main() and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslib.Timestamp'>\n",
      "10s at 0 of 56\n",
      "<class 'pandas._libs.tslib.Timestamp'>\n",
      "CPU times: user 2 s, sys: 136 ms, total: 2.13 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%time info_10s, info_hour = main() # This takes ~2,5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwelling id</th>\n",
       "      <th>recorded days</th>\n",
       "      <th>start date</th>\n",
       "      <th>stop date</th>\n",
       "      <th>total samples (per column, in thousands)</th>\n",
       "      <th>total NaN streaks</th>\n",
       "      <th>total NaN streaks &gt; 2</th>\n",
       "      <th>total NaNs [-]</th>\n",
       "      <th>total NaNs [%]</th>\n",
       "      <th>mean of NaNs</th>\n",
       "      <th>median of NaNs</th>\n",
       "      <th>std of NaNs</th>\n",
       "      <th>first highest NaN streak (%)</th>\n",
       "      <th>first highest NaN streak column</th>\n",
       "      <th>second highest NaN streak (%)</th>\n",
       "      <th>second highest NaN streak column</th>\n",
       "      <th>third highest NaN streak (%)</th>\n",
       "      <th>third highest NaN streak column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01S01W7548</td>\n",
       "      <td>83</td>\n",
       "      <td>2017-03-07 15:00:00</td>\n",
       "      <td>2017-05-30 13:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>528</td>\n",
       "      <td>26.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>eMeter</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>eMeter</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>eMeterReturn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dwelling id  recorded days          start date           stop date  \\\n",
       "0  P01S01W7548             83 2017-03-07 15:00:00 2017-05-30 13:00:00   \n",
       "\n",
       "   total samples (per column, in thousands)  total NaN streaks  \\\n",
       "0                                       2.0                 32   \n",
       "\n",
       "   total NaN streaks > 2  total NaNs [-]  total NaNs [%]  mean of NaNs  \\\n",
       "0                      9             528            26.5          16.5   \n",
       "\n",
       "   median of NaNs  std of NaNs  first highest NaN streak (%)  \\\n",
       "0             1.0         26.8                        0.0502   \n",
       "\n",
       "  first highest NaN streak column  second highest NaN streak (%)  \\\n",
       "0                          eMeter                         0.0502   \n",
       "\n",
       "  second highest NaN streak column  third highest NaN streak (%)  \\\n",
       "0                           eMeter                        0.0502   \n",
       "\n",
       "  third highest NaN streak column  \n",
       "0                    eMeterReturn  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "info_hour.to_csv('//datc//opschaler//dwelling_information//total_information//total_nan_information_hour.csv', sep='\\t', index=False)\n",
    "info_10s.to_csv('//datc//opschaler//dwelling_information//total_information//nan_information_10s.csv', sep='\\t', index=False)\n",
    "\n",
    "# Also save to Excel\n",
    "writer = pd.ExcelWriter('//datc//opschaler//dwelling_information//total_information//total_nan_information.xlsx')\n",
    "info_hour.to_excel(writer,'Hour dataframes', index=False)\n",
    "info_10s.to_excel(writer,'10s dataframes', index=False)\n",
    "writer.save()\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
