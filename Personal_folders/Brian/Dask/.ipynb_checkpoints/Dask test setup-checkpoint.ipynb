{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('default')\n",
    "import glob\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm\n",
    "from dask.distributed import Client, LocalCluster, progress, fire_and_forget\n",
    "from dask import delayed\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up LocalCluster & run it\n",
    "Might not be needed, but experienced that `processes=False, n_workers=1` are the best options to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>inproc://145.52.252.19/114317/1\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:8787/status' target='_blank'>http://localhost:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>48</li>\n",
       "  <li><b>Memory: </b>67.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='inproc://145.52.252.19/114317/1' processes=1 cores=48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster = LocalCluster(processes=False, n_workers=8)\n",
    "cluster = LocalCluster(processes=False, n_workers=1)\n",
    "#cpu_worker = cluster.workers[0]\n",
    "#cpu_worker.name = 'cpu'\n",
    "#cpu_worker.set_resources(CPU=90)\n",
    "\n",
    "client=Client(cluster, processes=True)\n",
    "#client=Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_weather_data():\n",
    "    \"\"\"\n",
    "    Reads in the weather Pandas DataFrame.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Check if UTC to gmt+1 conversion is being handled correctly\n",
    "    weather = pd.read_csv('//datc//opschaler//weather_data//knmi_10_min_raw_data//output//df_combined_uncleaned.csv',\n",
    "                          delimiter='\\t', comment='#',\n",
    "                          parse_dates=['datetime'])\n",
    "    weather = weather.set_index(['datetime'])\n",
    "    weather = reduce_memory(weather)\n",
    "    return weather\n",
    "\n",
    "\n",
    "def smartmeter_data():\n",
    "    \"\"\"\n",
    "    Reads in the file paths and dwelling id's of the smartmeter data.\n",
    "    :return: file_paths, dwelling_ids, both as lists.\n",
    "    \"\"\"\n",
    "    path = '//datc//opschaler//smartmeter_data//'\n",
    "    file_paths = np.array(glob.glob(path + \"*.csv\"))\n",
    "\n",
    "    print('Detected %s smartmeter_data files.' % len(file_paths))\n",
    "    dwelling_ids = np.array(list((map(lambda x: x[-15:-4], file_paths))))\n",
    "\n",
    "    return file_paths, dwelling_ids\n",
    "\n",
    "\n",
    "def reduce_memory(df):\n",
    "    \"\"\"\n",
    "    Reduces memory footprint of the input dataframe.\n",
    "    Changes float64 columns to float32 dtype.\n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    memory_before = df.memory_usage(deep=False).sum() / 2**30 # convert bytes to GB\n",
    "\n",
    "    for column in tqdm(columns):\n",
    "        if df[column].dtype == 'float64':\n",
    "            df[column] = df[column].astype('float32')\n",
    "        \n",
    "    memory_after = df.memory_usage(deep=False).sum() / 2**30 # convert bytes to GB\n",
    "    print('Memory uasge reduced from %.3f GB to %.3f GB' % (memory_before, memory_after))\n",
    "    \n",
    "    return df\n",
    "\n",
    "@delayed(nout=2)\n",
    "def clean_prepare_smart_gas(file_path, dwelling_id):\n",
    "    \"\"\"\n",
    "    Input is a dwelling_id.csv file.\n",
    "    Output are cleaned & prepared dataframes (smart, gas).\n",
    "\n",
    "    :param file_path: path to 'dwelling_id.csv' file\n",
    "    :return: Smart and gas Pandas DataFrames\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, delimiter=';', header=0)\n",
    "    df = df.rename(index=str, columns={'Timestamp': 'datetime', 'gasTimestamp': 'datetime'})\n",
    "    \n",
    "    # Split up the dataframe\n",
    "    smart = df.iloc[:, :7] # electricity part\n",
    "    gas = df.iloc[:, 7:] # gas part\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    try:\n",
    "        smart['datetime'] = pd.to_datetime(smart['datetime'])\n",
    "        gas['datetime'] = pd.to_datetime(gas['datetime'])\n",
    "    except:\n",
    "        print('datetime column contains non-datetime values')\n",
    "        smart = clean_datetime(smart)\n",
    "        gas = clean_datetime(gas)\n",
    "        smart['datetime'] = pd.to_datetime(smart['datetime'])\n",
    "        gas['datetime'] = pd.to_datetime(gas['datetime'])\n",
    "\n",
    "    smart = smart.set_index(['datetime'])\n",
    "    gas = gas.set_index(['datetime'])\n",
    "\n",
    "    smart = dask.delayed(reduce_memory)(smart) # Dask delay the 'reduce_memory' function with 'smart' as input variable for 'reduce_memory'\n",
    "    gas = dask.delayed(reduce_memorymemory)(gas)\n",
    "\n",
    "    return smart, gas\n",
    "\n",
    "\n",
    "@delayed\n",
    "def clean_datetime(df):\n",
    "    \"\"\"\n",
    "    TODO: Speed up the function\n",
    "    Input should be a df with a column called 'datetime'.\n",
    "    This function checks wether a row in the df.datetime column can be parsed to a Pandas datetime object,\n",
    "    by trying pd.to_datetime() on it.\n",
    "    If it fails it will replace that row with np.nan().\n",
    "    Finally this function will return the df with the NaN rows dropped.\n",
    "    It only drops the row if the datetime column contains a NaN.\n",
    "\n",
    "    :param df: Pandas DataFrame containing a datetime column called 'datetime'.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            pd.to_datetime(df.datetime[i])\n",
    "        except ValueError:\n",
    "            print('-----')\n",
    "            print('ValueError at index = %s' % i)\n",
    "            print(df.datetime[i])\n",
    "            df.datetime = df.datetime.replace(df.datetime[i], np.nan)\n",
    "    df = df.dropna(subset=['datetime'])\n",
    "    return df\n",
    "\n",
    "\n",
    "@delayed(nout=3)\n",
    "def resample_dfs(smart, gas, weather):\n",
    "    smart = smart.resample('10s').mean()\n",
    "    gas = gas.resample('H').mean()\n",
    "    weather = weather.resample('10min').mean()\n",
    "    return smart, gas, weather\n",
    "\n",
    "\n",
    "@delayed\n",
    "def create_hour_df(smart, gas, weather, dwelling_id):\n",
    "    gas['gasPower'] = gas['gasMeter'].diff()  # Calculate gasPower column\n",
    "    gas['gasPower'][0] = gas['gasPower'][1]  # Replace 1st entry (NaN) with 2nd entry\n",
    "    smart = smart.resample('H').mean()  # Down sample smart\n",
    "    weather = weather.resample('H').mean()  # Down sample weather\n",
    "    # Combine gas, smart, weather\n",
    "    df_hour = pd.merge(smart, gas, left_index=True, right_index=True)\n",
    "    df_hour = pd.merge(df_hour, weather, left_index=True, right_index=True)\n",
    "    df_hour['dwelling'] = dwelling_id\n",
    "    \n",
    "    return df_hour\n",
    "\n",
    "\n",
    "@delayed\n",
    "def create_10s_df(smart, gas, weather, dwelling_id):\n",
    "    gas = gas.resample('10s').ffill()  # Up sample gas to 10s\n",
    "    # Calculate gasPower column, is this rhe right way? Or should we ffill it?\n",
    "    # Currently this code makes it so there is one gasPower value per hour, we could ffill this also?\n",
    "    gas['gasPower'] = gas['gasMeter'].diff()\n",
    "    gas['gasPower'][0] = gas['gasPower'][1]  # Replace 1st entry (NaN) with 2nd entry\n",
    "    weather = weather.resample('10s').ffill()  # forward fill because the raw data is the 10 minute mean\n",
    "    # Combine gas, smart, weather\n",
    "    df_10s = pd.merge(smart, gas, left_index=True, right_index=True)\n",
    "    df_10s = pd.merge(df_10s, weather, left_index=True, right_index=True)\n",
    "    df_10s['dwelling'] = dwelling_id\n",
    "    return df_10s\n",
    "\n",
    "\n",
    "@delayed\n",
    "def plot_nans(df, dwelling_id, resample_to):\n",
    "    \"\"\"\n",
    "    Create a heatmap of the NaNs in the input DataFrame.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param df: String to resample to, for example '1T' or 'H'\n",
    "    :param dwelling_id: String\n",
    "    :return: Seaborn heatmap as a Figure\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    df = df.isnull()\n",
    "    # Downsample to make all data visible\n",
    "    df = df.resample(resample_to).sum()  # Downsample to make small NaNs visible\n",
    "    df = df.apply(lambda x: x > 0, 1)  # Replace values >0 with 1\n",
    "\n",
    "    # Reindex datetimes\n",
    "    # https://stackoverflow.com/questions/41046630/set-time-formatting-on-a-datetime-index-when-plotting-pandas-series\n",
    "    try:\n",
    "        df.index = df.index.to_period('D')\n",
    "    except:\n",
    "        print('plot_nans could not set df.index.to_period')\n",
    "\n",
    "    # Plot heatmap\n",
    "    n = int(len(df)*0.1)  # Choose amount of yticklabels to show\n",
    "\n",
    "    try:\n",
    "        fig = sns.heatmap(df, cmap='Reds', square=False, vmin=0, cbar=False, yticklabels=n*2, cbar_kws={})\n",
    "    except TypeError:\n",
    "        print('plot_nans ValueError')\n",
    "        fig = sns.heatmap(df, cmap='Reds', square=False, vmin=0, cbar=False, cbar_kws={})\n",
    "\n",
    "    # Set cbar ticks manually\n",
    "    #cbar = fig.collections[0].colorbar\n",
    "    #cbar.set_ticks([0, 1])\n",
    "    #cbar.set_ticklabels(['Not NaN', 'NaN'])\n",
    "\n",
    "    # Correct layout\n",
    "    fig.invert_yaxis()\n",
    "    fig.tick_params(axis='x', rotation=90)\n",
    "    fig.tick_params(axis='y', rotation=0)\n",
    "    fig.set(xlabel='Column [-]', ylabel='Index [-]')\n",
    "    plt.title('Dwelling ID: '+dwelling_id)\n",
    "\n",
    "    fig = fig.get_figure()\n",
    "    #fig.tight_layout()\n",
    "    #fig.show()\n",
    "    #print('Saving heatmap')\n",
    "    #fig.savefig('F://datc//opschaler//nan_information//figures//' + dwelling_id + '.png', dpi=1200)\n",
    "    #savefig crashes dask\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "@delayed\n",
    "def df_nan_checker(df, threshold_percentage):\n",
    "    \"\"\"\n",
    "    TODO: Parellalize, as in one column per core/worker?\n",
    "    Checks each column in the input dataframe for NaNs.\n",
    "    Outputs the amount of NaNs behind each other, including the start and stop index, per column as a sublist.\n",
    "    For example when the dataframe has three columns.\n",
    "    Output is in the form of:\n",
    "    [[column_one_info], [column_two_info], [column_three_info]]\n",
    "    With the column_..._info being in the form of:\n",
    "    [start_index, stop_index, amount_of_NaNs]\n",
    "\n",
    "    :param df: Pandas DataFrame\n",
    "    :param threshold_percentage: Filter output based on NaN streaks being larger than x % of the total length of the dataframe.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    df = df.isnull()\n",
    "    output = []\n",
    "    length = len(columns)\n",
    "    \n",
    "    \n",
    "    @delayed\n",
    "    def check_rows(df, column_name):\n",
    "        column_info = []\n",
    "        temp = []\n",
    "        x = False\n",
    "\n",
    "        for j, value in enumerate(df[column_name]):\n",
    "            if x == False and value == True:\n",
    "                temp.append(df.index[j])\n",
    "                x = True\n",
    "            elif x == True and value == True:\n",
    "                temp.append(df.index[j])\n",
    "            elif x == True and value == False:\n",
    "                column_info.append(temp)\n",
    "                temp = []\n",
    "                x = False\n",
    "\n",
    "        lengths = []\n",
    "\n",
    "        for array in column_info:\n",
    "            lengths.append([array[0], array[-1], len(array)])\n",
    "\n",
    "        return lengths\n",
    "\n",
    "    \n",
    "    for i in range(length):\n",
    "        lengths = check_rows(df, columns[i])\n",
    "        output.append(lengths)\n",
    "    \n",
    "    @delayed\n",
    "    def list_to_df(output):\n",
    "        # Convert df_info to a readable dataframe instead of list\n",
    "\n",
    "        \"\"\"\n",
    "        Row per column from the 'output' list\n",
    "        Columns: start-index, stop-index, NaN streak\n",
    "        \"\"\"\n",
    "\n",
    "        df_info = pd.DataFrame(columns=['Column name', 'Start index', 'Stop index', 'Amount of NaNs'])\n",
    "        length = len(output)\n",
    "        column_names = []\n",
    "        starts = []\n",
    "        stops = []\n",
    "        amounts = []\n",
    "\n",
    "        for column in range(length):\n",
    "            #print('At iteration %s of %s' % (column, length))\n",
    "            for i in range(len(output[column])):\n",
    "                column_names.append(df.columns[column])\n",
    "                starts.append(output[column][i][0])\n",
    "                stops.append(output[column][i][1])\n",
    "                amounts.append(output[column][i][2])\n",
    "\n",
    "        print('Appending NaN info to df')\n",
    "        # Convert list to pd series\n",
    "        column_names = pd.Series(column_names)\n",
    "        starts = pd.Series(starts)\n",
    "        stops = pd.Series(stops)\n",
    "        amounts = pd.Series(amounts)\n",
    "        # Append pd series to a column\n",
    "        df_info['Column name'] = column_names.values\n",
    "        df_info['Start index'] = starts.values\n",
    "        df_info['Stop index'] = stops.values\n",
    "        df_info['Amount of NaNs'] = amounts.values\n",
    "\n",
    "        percentage = (df_info['Amount of NaNs'] / len(df)) * 100\n",
    "        df_info.drop(df_info[percentage < threshold_percentage].index, inplace=True)\n",
    "        return df_info\n",
    "\n",
    "    df_info = list_to_df(output)\n",
    "    \n",
    "    return df_info\n",
    "\n",
    "\n",
    "def save_df_unprocessed(df, dwelling_id):\n",
    "    \"\"\"\n",
    "    Save unprocessed dataframe.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param dwelling_id: String\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dir = 'F://datc//opschaler//combined_gas_smart_weather_dfs//unprocessed//'\n",
    "    df.to_csv(dir + dwelling_id + '.csv', sep='\\t', index=True)\n",
    "    print('Saved unprocessed df: %s' % dwelling_id)\n",
    "    return\n",
    "\n",
    "\n",
    "@delayed\n",
    "def drop_nan_streaks_above_threshold(df, df_nan_table, thresholds):\n",
    "    \"\"\"\n",
    "    Drops NaN streaks from the df when they are larger then the threshold value.\n",
    "    This function also inputs df_nan_table because it already has been made in the smart_gas_nan_checker.\n",
    "    :param df: Pandas DataDrame to process NaNs off\n",
    "    :param df_nan_table: NaN info Pandas DataFrame of the input df\n",
    "    :param thresholds: Dictionary {'column_name':column_threshold}, column_threshold has to be an integer.\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    df_nan_table = df_nan_table.compute()\n",
    "\n",
    "    # Check for NaN streaks > threshold and drop them from the df\n",
    "    length = len(df_nan_table['Amount of NaNs'])\n",
    "    print('df_nan_table length: %s' % length)\n",
    "\n",
    "    indices_to_drop = []\n",
    "    for i, amount in enumerate(df_nan_table['Amount of NaNs']):\n",
    "        selected_column = df_nan_table['Column name'][i]\n",
    "        try:\n",
    "            if amount > thresholds[selected_column]:\n",
    "                start_index = (df_nan_table['Start index'][i])\n",
    "                stop_index = (df_nan_table['Stop index'][i])\n",
    "                indices = df[start_index:stop_index].index\n",
    "                print('Enumeration %s of %s | From \\t %s \\t to \\t %s | column %s | NaN streak length: %s'\n",
    "                      % (i, length, start_index, stop_index, selected_column, (len(indices))))\n",
    "                try:\n",
    "                    indices_to_drop += indices\n",
    "                except:\n",
    "                    print('Could not add indices to indices_to_drop list')\n",
    "            else:\n",
    "                #print('amount < threshold')\n",
    "                pass\n",
    "        except:\n",
    "            #print('No threshold detected for %s' % selected_column)\n",
    "            pass\n",
    "\n",
    "    print('Dropping NaN streaks > threshold')\n",
    "    l1 = len(df)\n",
    "    df = df.drop(indices_to_drop)\n",
    "    l2 = len(df)\n",
    "    print('Removed %s rows' % (l1-l2))\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_df_processed(df, dwelling_id):\n",
    "    \"\"\"\n",
    "    Save interpolated dataframe.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param dwelling_id: String\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dir = '//datc//opschaler//combined_gas_smart_weather_dfs//processed//'\n",
    "    df.to_csv(dir + dwelling_id + '.csv', sep='\\t', index=True)\n",
    "    print('Saved processed df: %s' % dwelling_id)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 271.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.023 GB to 0.012 GB\n",
      "Detected 56 smartmeter_data files.\n",
      "CPU times: user 654 ms, sys: 71.2 ms, total: 725 ms\n",
      "Wall time: 805 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      " 17%|█▋        | 1/6 [00:00<00:00,  8.36it/s]\n",
      " 33%|███▎      | 2/6 [00:01<00:01,  3.98it/s]\n",
      " 50%|█████     | 3/6 [00:03<00:01,  1.66it/s]\n",
      " 67%|██████▋   | 4/6 [00:05<00:01,  1.21it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.39s/it]\n",
      "\n",
      " 17%|█▋        | 1/6 [00:03<00:01,  2.53it/s]\u001b[A\u001b[A\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.009 GB to 0.005 GB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:14<00:00,  2.60s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory uasge reduced from 0.012 GB to 0.007 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:09<00:05,  1.86s/it]\n",
      " 83%|████████▎ | 5/6 [00:11<00:01,  1.85s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.85it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:13<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.003 GB to 0.003 GB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory uasge reduced from 0.002 GB to 0.002 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      " 17%|█▋        | 1/6 [00:04<00:07,  1.58s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  2.59it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|███▎      | 2/6 [00:08<00:10,  2.71s/it]\n",
      "\n",
      " 33%|███▎      | 2/6 [00:01<00:00, 13.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|███▎      | 2/6 [00:06<00:04,  1.25s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:11<00:07,  2.46s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:04<00:01,  4.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [00:04<00:01,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:04<00:05,  1.41s/it]\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:02<00:01,  4.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.017 GB to 0.010 GB\n",
      "Memory uasge reduced from 0.005 GB to 0.004 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:02<00:01,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:02<00:01,  4.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:13<00:05,  2.66s/it]\n",
      " 50%|█████     | 3/6 [00:09<00:05,  1.87s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:04<00:03,  1.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:04<00:04,  1.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:03<00:04,  1.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:01<00:01,  2.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:10<00:03,  1.96s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:01<00:00,  5.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.53s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:01<00:00,  6.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:06<00:03,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:06<00:03,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:05<00:03,  1.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:03<00:02,  1.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:08<00:03,  1.56s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:11<00:01,  1.78s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:04<00:04,  1.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:02<00:02,  1.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.036 GB to 0.021 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.54s/it]\u001b[A\n",
      "distributed.worker - WARNING -  Compute Failed\n",
      "Function:  clean_prepare_smart_gas\n",
      "args:      ('//datc//opschaler//smartmeter_data/export_P01S01W4569.csv', 'P01S01W4569')\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'tqdm' object has no attribute 'pos'\",)\n",
      "\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.45s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:07<00:02,  1.34s/it]distributed.worker - WARNING -  Compute Failed\n",
      "Function:  clean_prepare_smart_gas\n",
      "args:      ('//datc//opschaler//smartmeter_data/export_P01S01W6835.csv', 'P01S01W6835')\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'tqdm' object has no attribute 'pos'\",)\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:12<00:00,  1.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:05<00:03,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:07<00:02,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:07<00:01,  1.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:04<00:02,  1.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.037 GB to 0.021 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:05<00:04,  1.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 1/6 [00:00<00:00,  8.47it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:04<00:02,  1.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.010 GB to 0.008 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:08<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:05<00:02,  1.01s/it]\u001b[A\u001b[A\u001b[Adistributed.worker - WARNING -  Compute Failed\n",
      "Function:  clean_prepare_smart_gas\n",
      "args:      ('//datc//opschaler//smartmeter_data/export_P01S01W8239.csv', 'P01S01W8239')\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'tqdm' object has no attribute 'pos'\",)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:01<00:01,  3.72it/s]distributed.worker - WARNING -  Compute Failed\n",
      "Function:  clean_prepare_smart_gas\n",
      "args:      ('//datc//opschaler//smartmeter_data/export_P01S01W1347.csv', 'P01S01W1347')\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'tqdm' object has no attribute 'pos'\",)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:05<00:03,  1.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:10<00:01,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [00:03<00:02,  1.28it/s]\n",
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.37s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:07<00:00,  1.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.042 GB to 0.024 GBMemory uasge reduced from 0.038 GB to 0.022 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:06<00:01,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:07<00:02,  1.47s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.037 GB to 0.021 GB\n",
      "Memory uasge reduced from 0.036 GB to 0.021 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.39it/s]\n",
      "\n",
      " 17%|█▋        | 1/6 [00:00<00:00,  6.84it/s]\u001b[A\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:07<00:01,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.05s/it]\u001b[A\u001b[A\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  4.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.037 GB to 0.021 GB\n",
      "Memory uasge reduced from 0.011 GB to 0.008 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.012 GB to 0.009 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\u001b[A\u001b[A\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.50it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:01<00:00,  4.11it/s]\n",
      "\n",
      "distributed.worker - WARNING -  Compute Failed\n",
      "Function:  clean_prepare_smart_gas\n",
      "args:      ('//datc//opschaler//smartmeter_data/export_P01S01W7548.csv', 'P01S01W7548')\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'tqdm' object has no attribute 'pos'\",)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\u001b[Adistributed.worker - WARNING -  Compute Failed\n",
      "Function:  clean_prepare_smart_gas\n",
      "args:      ('//datc//opschaler//smartmeter_data/export_P01S01W6959.csv', 'P01S01W6959')\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'tqdm' object has no attribute 'pos'\",)\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:01<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.051 GB to 0.029 GB\n",
      "Memory uasge reduced from 0.010 GB to 0.008 GB\n",
      "Memory uasge reduced from 0.010 GB to 0.008 GB\n",
      "Memory uasge reduced from 0.054 GB to 0.031 GB\n",
      "Memory uasge reduced from 0.011 GB to 0.008 GB\n",
      "Memory uasge reduced from 0.015 GB to 0.011 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.015 GB to 0.012 GB\n",
      "Memory uasge reduced from 0.078 GB to 0.045 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory uasge reduced from 0.022 GB to 0.017 GB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "client.restart()\n",
    "\n",
    "weather = read_weather_data()\n",
    "\n",
    "file_paths, dwelling_ids = smartmeter_data()\n",
    "\n",
    "file_paths = file_paths[:20]\n",
    "\n",
    "dfs_hour = []\n",
    "dfs_10s = []\n",
    "dfs_nan_table_10s = []\n",
    "dfs_nan_table_hour = []\n",
    "\n",
    "dfs_10s_partly_processed = []\n",
    "dfs_hour_partly_processed = []\n",
    "\n",
    "smarts = []\n",
    "gass = []\n",
    "\n",
    "\n",
    "for i, path in enumerate(file_paths):\n",
    "    dwelling_id = dwelling_ids[i]\n",
    "    \n",
    "    smart, gas = clean_prepare_smart_gas(path, dwelling_id)\n",
    "    \n",
    "    # client.persist: Start computing these variables and keep them in memory\n",
    "    smart = smart.persist()\n",
    "    gas = gas.persist()\n",
    "\n",
    "    #smart, gas, weather_rs = resample_dfs(smart, gas, weather)\n",
    "    \n",
    "    #smart = smart.persist()\n",
    "    #gas = gas.persist()\n",
    "    #weather_rs = weather_rs.persist()\n",
    "    \n",
    "    #df_hour = create_hour_df(smart, gas, weather, dwelling_id)\n",
    "    #df_10s = create_10s_df(smart, gas, weather, dwelling_id)\n",
    "    \n",
    "    #df_hour = df_hour.persist()\n",
    "    #df_10s = df_10s.persist()\n",
    "    \n",
    "    #Slow, plus low cpu usage...\n",
    "    #fig = plot_nans(df_10s, dwelling_id+' 10s sample rate', '1T')\n",
    "    \n",
    "    #df_nan_table_10s = df_nan_checker(df_10s, 0)\n",
    "    #df_nan_table_hour = df_nan_checker(df_hour, 0)\n",
    "    \n",
    "    #df_nan_table_10s = df_nan_table_10s.persist()\n",
    "    #df_nan_table_hour = df_nan_table_hour.persist()\n",
    "    \n",
    "    thresholds_10s = {'eMeter': 6, 'ePower': 6, 'gasMeter': 72, 'T': 36, 'Q': 18}\n",
    "    #df_10s_partly_processed = drop_nan_streaks_above_threshold(df_10s, df_nan_table_10s, thresholds_10s)\n",
    "    #df_10s_partly_processed = df_10s_partly_processed.persist()\n",
    "    \n",
    "    thresholds_hour = {'eMeter': 2, 'ePower': 2, 'gasMeter': 2, 'T': 1, 'Q': 1}\n",
    "    #df_hour_partly_processed = drop_nan_streaks_above_threshold(df_hour, df_nan_table_hour, thresholds_hour)\n",
    "    #df_hour_partly_processed = df_hour_partly_processed.persist()\n",
    "    \n",
    "    smarts.append(smart)\n",
    "    gass.append(gas)\n",
    "    #dfs_hour.append(df_hour)\n",
    "    #dfs_10s.append(df_10s)\n",
    "    #dfs_nan_table_10s.append(df_nan_table_10s)\n",
    "    #dfs_nan_table_hour.append(df_nan_table_hour)\n",
    "    \n",
    "    #dfs_10s_partly_processed.append(df_10s_partly_processed)\n",
    "    #dfs_hour_partly_processed.append(df_hour_partly_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_gdbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/worker.py\u001b[0m in \u001b[0;36mdumps_function\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <function df_nan_checker.<locals>.list_to_df at 0x7fd67129cd08>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/protocol/pickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'df_nan_checker.<locals>.list_to_df'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0016c59e562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdfs_hour_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_hour\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdfs_nan_table_10s_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_nan_table_10s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdfs_nan_table_hour_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_nan_table_hour\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, collections, sync, optimize_graph, workers, allow_other_workers, resources, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2378\u001b[0m                                               \u001b[0muser_priority\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpriority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m                                               \u001b[0mfifo_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfifo_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2380\u001b[0;31m                                               actors=actors)\n\u001b[0m\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_graph_to_futures\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, priority, user_priority, resources, retries, fifo_timeout, actors)\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             self._send_to_scheduler({'op': 'update-graph',\n\u001b[0;32m-> 2154\u001b[0;31m                                      \u001b[0;34m'tasks'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdumps_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsk3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2155\u001b[0m                                      \u001b[0;34m'dependencies'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m                                      \u001b[0;34m'keys'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/cytoolz/dicttoolz.pyx\u001b[0m in \u001b[0;36mcytoolz.dicttoolz.valmap (cytoolz/dicttoolz.c:3277)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/cytoolz/dicttoolz.pyx\u001b[0m in \u001b[0;36mcytoolz.dicttoolz.valmap (cytoolz/dicttoolz.c:3124)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/worker.py\u001b[0m in \u001b[0;36mdumps_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_maybe_complex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             return {'function': dumps_function(task[0]),\n\u001b[0m\u001b[1;32m    878\u001b[0m                     'args': warn_dumps(task[1:])}\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/worker.py\u001b[0m in \u001b[0;36mdumps_function\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/16011015/.local/lib/python3.6/site-packages/distributed/protocol/pickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to serialize %s. Exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/cloudpickle/cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/cloudpickle/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_addons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'recursion'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/cloudpickle/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mmodname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhichmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;31m# print('which gives %s %s %s' % (modname, obj, name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mwhichmodule\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/seaborn/external/six.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"__file__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0m_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/seaborn/external/six.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/seaborn/external/six.py\u001b[0m in \u001b[0;36m_import_module\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;34m\"\"\"Import module, returning the module after the last dot.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/dbm/gnu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Provide the _gdbm module as a dbm submodule.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_gdbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_gdbm'"
     ]
    }
   ],
   "source": [
    "dfs_10s_results = []\n",
    "dfs_hour_results = []\n",
    "\n",
    "dfs_nan_table_10s_results = []\n",
    "dfs_nan_table_hour_results = []\n",
    "\n",
    "dfs_10s_partly_processed_results = []\n",
    "dfs_hour_partly_processed_results = []\n",
    "\n",
    "for i in range(len(dfs_nan_table_10s)):\n",
    "    dfs_10s_results.append(client.compute(dfs_10s[i].compute()))\n",
    "    dfs_hour_results.append(client.compute(dfs_hour[i].compute()))\n",
    "    \n",
    "    dfs_nan_table_10s_results.append(client.compute(dfs_nan_table_10s[i].compute()))\n",
    "    dfs_nan_table_hour_results.append(client.compute(dfs_nan_table_hour[i].compute()))\n",
    "    \n",
    "    dfs_10s_partly_processed_results.append(client.compute(dfs_10s_partly_processed[i].compute()))\n",
    "    dfs_hour_partly_processed_results.append(client.compute(dfs_hour_partly_processed[i].compute()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b2802ce5a321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfs_hour_partly_processed_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dfs_hour_partly_processed_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = []\n",
    "for i in range(len(dfs_10s_partly_processed)):\n",
    "    dwelling_id = dwelling_ids[i]\n",
    "    df = dfs_10s_partly_processed[i].compute()\n",
    "    z = client.submit(save_df_processed, df, dwelling_id+'_10s')\n",
    "    zz.append(z) # This makes it run in parallel?\n",
    "    print('Finished saving %s' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = []\n",
    "for i in range(len(dfs_hour_partly_processed)):\n",
    "    dwelling_id = dwelling_ids[i]\n",
    "    df = dfs_hour_partly_processed[i].compute()\n",
    "    z = client.submit(save_df_processed, df, dwelling_id+'_hour')\n",
    "    zz.append(z) # This makes it run in parallel?\n",
    "    print('Finished saving %s' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = []\n",
    "for i in range(len(dfs_10s_partly_processed)):\n",
    "    dwelling_id = dwelling_ids[i]\n",
    "    df = dfs_10s_partly_processed[i].compute()\n",
    "    z = client.submit(save_df_processed, df, dwelling_id+'_10s')\n",
    "    zz.append(z) # This makes it run in parallel?\n",
    "    print('Finished saving %s' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = []\n",
    "for i in range(len(dfs_hour_partly_processed)):\n",
    "    dwelling_id = dwelling_ids[i]\n",
    "    df = dfs_hour_partly_processed[i].compute()\n",
    "    z = client.submit(save_df_processed, df, dwelling_id+'_hour')\n",
    "    zz.append(z) # This makes it run in parallel?\n",
    "    print('Finished saving %s' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframes\n",
    "Some unprocessed ones take 230 seconds to save.\n",
    "It is in parallel, but it is still slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Little trick to force run this save function in parallel.\n",
    "Force compute the df, then submit the save_df_unprocessed function to the scheduler. \n",
    "Loop over this, client will process save_df_unprocessed in the back end.\n",
    "\"\"\"\n",
    "\n",
    "%%time\n",
    "for i in range (len(dfs_10s)):\n",
    "    df = dfs_10s[i].compute()\n",
    "    z = client.submit(save_df_unprocessed, df, (dwelling_ids[i]+'_10s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save[1].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfs_hour = dask.compute(dfs_hour)\n",
    "dfs_10s = dask.compute(dfs_10s)\n",
    "dfs_nan_table_10s = dask.compute(dfs_nan_table_10s)\n",
    "dfs_nan_table_hour = dask.compute(dfs_nan_table_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(dfs_hour[0])):\n",
    "    save_df_unprocessed(dfs_10s[0][i], dwelling_ids[i]+'_10s')\n",
    "    save_df_unprocessed(dfs_hour[0][i], dwelling_ids[i]+'_hour')\n",
    "    dfs_nan_table_10s[0][0][i].to_csv('F://datc//opschaler//nan_information//'+dwelling_ids[i]+'_10s.csv', sep='\\t')\n",
    "    dfs_nan_table_hour[0][0][i].to_csv('F://datc//opschaler//nan_information//' + dwelling_ids[i] + '_hour.csv', sep='\\t')\n",
    "    print('Finished iteration %s out of %s.' % (i, len(dfs_hour[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
